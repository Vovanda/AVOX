{
  "id": "a328e37a-9361-4ed2-9cca-6a970f219df1",
  "data": {
    "nodes": [
      {
        "id": "ChatInput-mrZxx",
        "type": "genericNode",
        "position": {
          "x": 823.0416333419151,
          "y": 773.6207796823591
        },
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-mrZxx",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.2.0",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "advanced": false,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Вео"
              },
              "sender": {
                "advanced": true,
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Клиент"
              },
              "session_id": {
                "advanced": false,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "advanced": false,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ChatInput"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 435
        },
        "dragging": false
      },
      {
        "id": "ParseData-sAWkP",
        "type": "genericNode",
        "position": {
          "x": 1700.9554282213755,
          "y": 1829.432577046183
        },
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data",
          "id": "ParseData-sAWkP",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Документ: {source}\n{description}\n{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "hidden": null,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ParseData"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 341
        },
        "dragging": false
      },
      {
        "id": "AstraDB-XEb8a",
        "type": "genericNode",
        "position": {
          "x": 2582.959289328254,
          "y": 140.44610407052937
        },
        "data": {
          "id": "AstraDB-XEb8a",
          "node": {
            "template": {
              "_type": "Component",
              "embedding_model": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_model",
                "value": "",
                "display_name": "Embedding Model",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Specify the Embedding Model. Not required for Astra Vectorize collections.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "advanced_search_filter": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "advanced_search_filter",
                "value": {},
                "display_name": "Search Metadata Filter",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of filters to apply to the search query.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "api_endpoint": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_endpoint",
                "value": "AVOX_VDB",
                "display_name": "Astra DB API Endpoint",
                "advanced": true,
                "dynamic": false,
                "info": "The API Endpoint for the Astra DB instance. Supercedes database selection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "astradb_vectorstore_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "astradb_vectorstore_kwargs",
                "value": {},
                "display_name": "AstraDBVectorStore Parameters",
                "advanced": true,
                "dynamic": false,
                "info": "Optional dictionary of additional parameters for the AstraDBVectorStore.",
                "title_case": false,
                "type": "NestedDict",
                "_input_type": "NestedDictInput"
              },
              "autodetect_collection": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "autodetect_collection",
                "value": true,
                "display_name": "Autodetect Collection",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to autodetect the collection.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections import defaultdict\nfrom dataclasses import asdict, dataclass, field\n\nfrom astrapy import AstraDBAdmin, DataAPIClient, Database\nfrom astrapy.info import CollectionDescriptor\nfrom langchain_astradb import AstraDBVectorStore, CollectionVectorServiceOptions\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import FloatInput, NestedDictInput\nfrom langflow.io import (\n    BoolInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\nfrom langflow.utils.version import get_version_info\n\n\nclass AstraDBVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Ingest and search documents in Astra DB\"\n    documentation: str = \"https://docs.datastax.com/en/langflow/astra-components.html\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    _cached_vector_store: AstraDBVectorStore | None = None\n\n    @dataclass\n    class NewDatabaseInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_database\",\n                        \"description\": \"\",\n                        \"display_name\": \"Create new database\",\n                        \"field_order\": [\"new_database_name\", \"cloud_provider\", \"region\"],\n                        \"template\": {\n                            \"new_database_name\": StrInput(\n                                name=\"new_database_name\",\n                                display_name=\"Name\",\n                                info=\"Name of the new database to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"cloud_provider\": DropdownInput(\n                                name=\"cloud_provider\",\n                                display_name=\"Cloud provider\",\n                                info=\"Cloud provider for the new database.\",\n                                options=[\"Amazon Web Services\", \"Google Cloud Platform\", \"Microsoft Azure\"],\n                                required=True,\n                                real_time_refresh=True,\n                            ),\n                            \"region\": DropdownInput(\n                                name=\"region\",\n                                display_name=\"Region\",\n                                info=\"Region for the new database.\",\n                                options=[],\n                                required=True,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    @dataclass\n    class NewCollectionInput:\n        functionality: str = \"create\"\n        fields: dict[str, dict] = field(\n            default_factory=lambda: {\n                \"data\": {\n                    \"node\": {\n                        \"name\": \"create_collection\",\n                        \"description\": \"\",\n                        \"display_name\": \"Create new collection\",\n                        \"field_order\": [\n                            \"new_collection_name\",\n                            \"embedding_generation_provider\",\n                            \"embedding_generation_model\",\n                            \"dimension\",\n                        ],\n                        \"template\": {\n                            \"new_collection_name\": StrInput(\n                                name=\"new_collection_name\",\n                                display_name=\"Name\",\n                                info=\"Name of the new collection to create in Astra DB.\",\n                                required=True,\n                            ),\n                            \"embedding_generation_provider\": DropdownInput(\n                                name=\"embedding_generation_provider\",\n                                display_name=\"Embedding generation method\",\n                                info=\"Provider to use for generating embeddings.\",\n                                real_time_refresh=True,\n                                required=True,\n                                options=[\"Bring your own\", \"Nvidia\"],\n                            ),\n                            \"embedding_generation_model\": DropdownInput(\n                                name=\"embedding_generation_model\",\n                                display_name=\"Embedding model\",\n                                info=\"Model to use for generating embeddings.\",\n                                required=True,\n                                options=[],\n                            ),\n                            \"dimension\": IntInput(\n                                name=\"dimension\",\n                                display_name=\"Dimensions (Required only for `Bring your own`)\",\n                                info=\"Dimensions of the embeddings to generate.\",\n                                required=False,\n                                value=1024,\n                            ),\n                        },\n                    },\n                }\n            }\n        )\n\n    inputs = [\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        StrInput(\n            name=\"environment\",\n            display_name=\"Environment\",\n            info=\"The environment for the Astra DB API Endpoint.\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        DropdownInput(\n            name=\"database_name\",\n            display_name=\"Database\",\n            info=\"The Database name for the Astra DB instance.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewDatabaseInput()),\n            combobox=True,\n        ),\n        StrInput(\n            name=\"api_endpoint\",\n            display_name=\"Astra DB API Endpoint\",\n            info=\"The API Endpoint for the Astra DB instance. Supercedes database selection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"collection_name\",\n            display_name=\"Collection\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n            refresh_button=True,\n            real_time_refresh=True,\n            dialog_inputs=asdict(NewCollectionInput()),\n            combobox=True,\n            advanced=True,\n        ),\n        StrInput(\n            name=\"keyspace\",\n            display_name=\"Keyspace\",\n            info=\"Optional keyspace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"embedding_choice\",\n            display_name=\"Embedding Model or Astra Vectorize\",\n            info=\"Choose an embedding model or use Astra Vectorize.\",\n            options=[\"Embedding Model\", \"Astra Vectorize\"],\n            value=\"Embedding Model\",\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        HandleInput(\n            name=\"embedding_model\",\n            display_name=\"Embedding Model\",\n            input_types=[\"Embeddings\"],\n            info=\"Specify the Embedding Model. Not required for Astra Vectorize collections.\",\n            required=False,\n        ),\n        *LCVectorStoreComponent.inputs,\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Search Results\",\n            info=\"Number of search results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. \"\n            \"(when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"advanced_search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"autodetect_collection\",\n            display_name=\"Autodetect Collection\",\n            info=\"Boolean flag to determine whether to autodetect the collection.\",\n            advanced=True,\n            value=True,\n        ),\n        StrInput(\n            name=\"content_field\",\n            display_name=\"Content Field\",\n            info=\"Field to use as the text content field for the vector store.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"deletion_field\",\n            display_name=\"Deletion Based On Field\",\n            info=\"When this parameter is provided, documents in the target collection with \"\n            \"metadata field values matching the input metadata field value will be deleted \"\n            \"before new data is loaded.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"ignore_invalid_documents\",\n            display_name=\"Ignore Invalid Documents\",\n            info=\"Boolean flag to determine whether to ignore invalid documents at runtime.\",\n            advanced=True,\n        ),\n        NestedDictInput(\n            name=\"astradb_vectorstore_kwargs\",\n            display_name=\"AstraDBVectorStore Parameters\",\n            info=\"Optional dictionary of additional parameters for the AstraDBVectorStore.\",\n            advanced=True,\n        ),\n    ]\n\n    @classmethod\n    def map_cloud_providers(cls):\n        # TODO: Programmatically fetch the regions for each cloud provider\n        return {\n            \"Amazon Web Services\": {\n                \"id\": \"aws\",\n                \"regions\": [\"us-east-2\", \"ap-south-1\", \"eu-west-1\"],\n            },\n            \"Google Cloud Platform\": {\n                \"id\": \"gcp\",\n                \"regions\": [\"us-east1\"],\n            },\n            \"Microsoft Azure\": {\n                \"id\": \"azure\",\n                \"regions\": [\"westus3\"],\n            },\n        }\n\n    @classmethod\n    def get_vectorize_providers(cls, token: str, environment: str | None = None, api_endpoint: str | None = None):\n        try:\n            # Get the admin object\n            admin = AstraDBAdmin(token=token, environment=environment)\n            db_admin = admin.get_database_admin(api_endpoint=api_endpoint)\n\n            # Get the list of embedding providers\n            embedding_providers = db_admin.find_embedding_providers().as_dict()\n\n            vectorize_providers_mapping = {}\n            # Map the provider display name to the provider key and models\n            for provider_key, provider_data in embedding_providers[\"embeddingProviders\"].items():\n                # Get the provider display name and models\n                display_name = provider_data[\"displayName\"]\n                models = [model[\"name\"] for model in provider_data[\"models\"]]\n\n                # Build our mapping\n                vectorize_providers_mapping[display_name] = [provider_key, models]\n\n            # Sort the resulting dictionary\n            return defaultdict(list, dict(sorted(vectorize_providers_mapping.items())))\n        except Exception as e:\n            msg = f\"Error fetching vectorize providers: {e}\"\n            raise ValueError(msg) from e\n\n    @classmethod\n    async def create_database_api(\n        cls,\n        new_database_name: str,\n        cloud_provider: str,\n        region: str,\n        token: str,\n        environment: str | None = None,\n        keyspace: str | None = None,\n    ):\n        client = DataAPIClient(token=token, environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Call the create database function\n        return await admin_client.async_create_database(\n            name=new_database_name,\n            cloud_provider=cls.map_cloud_providers()[cloud_provider][\"id\"],\n            region=region,\n            keyspace=keyspace,\n            wait_until_active=False,\n        )\n\n    @classmethod\n    async def create_collection_api(\n        cls,\n        new_collection_name: str,\n        token: str,\n        api_endpoint: str,\n        environment: str | None = None,\n        keyspace: str | None = None,\n        dimension: int | None = None,\n        embedding_generation_provider: str | None = None,\n        embedding_generation_model: str | None = None,\n    ):\n        # Create the data API client\n        client = DataAPIClient(token=token, environment=environment)\n\n        # Get the database object\n        database = client.get_async_database(api_endpoint=api_endpoint, token=token)\n\n        # Build vectorize options, if needed\n        vectorize_options = None\n        if not dimension:\n            vectorize_options = CollectionVectorServiceOptions(\n                provider=cls.get_vectorize_providers(\n                    token=token, environment=environment, api_endpoint=api_endpoint\n                ).get(embedding_generation_provider, [None, []])[0],\n                model_name=embedding_generation_model,\n            )\n\n        # Create the collection\n        return await database.create_collection(\n            name=new_collection_name,\n            keyspace=keyspace,\n            dimension=dimension,\n            service=vectorize_options,\n        )\n\n    @classmethod\n    def get_database_list_static(cls, token: str, environment: str | None = None):\n        client = DataAPIClient(token=token, environment=environment)\n\n        # Get the admin object\n        admin_client = client.get_admin(token=token)\n\n        # Get the list of databases\n        db_list = list(admin_client.list_databases())\n\n        # Set the environment properly\n        env_string = \"\"\n        if environment and environment != \"prod\":\n            env_string = f\"-{environment}\"\n\n        # Generate the api endpoint for each database\n        db_info_dict = {}\n        for db in db_list:\n            try:\n                # Get the API endpoint for the database\n                api_endpoint = f\"https://{db.info.id}-{db.info.region}.apps.astra{env_string}.datastax.com\"\n\n                # Get the number of collections\n                try:\n                    num_collections = len(\n                        list(\n                            client.get_database(\n                                api_endpoint=api_endpoint, token=token, keyspace=db.info.keyspace\n                            ).list_collection_names(keyspace=db.info.keyspace)\n                        )\n                    )\n                except Exception:  # noqa: BLE001\n                    num_collections = 0\n                    if db.status != \"PENDING\":\n                        continue\n\n                # Add the database to the dictionary\n                db_info_dict[db.info.name] = {\n                    \"api_endpoint\": api_endpoint,\n                    \"collections\": num_collections,\n                    \"status\": db.status if db.status != \"ACTIVE\" else None,\n                }\n            except Exception:  # noqa: BLE001, S110\n                pass\n\n        return db_info_dict\n\n    def get_database_list(self):\n        return self.get_database_list_static(token=self.token, environment=self.environment)\n\n    @classmethod\n    def get_api_endpoint_static(\n        cls,\n        token: str,\n        environment: str | None = None,\n        api_endpoint: str | None = None,\n        database_name: str | None = None,\n    ):\n        # If the api_endpoint is set, return it\n        if api_endpoint:\n            return api_endpoint\n\n        # Check if the database_name is like a url\n        if database_name and database_name.startswith(\"https://\"):\n            return database_name\n\n        # If the database is not set, nothing we can do.\n        if not database_name:\n            return None\n\n        # Grab the database object\n        db = cls.get_database_list_static(token=token, environment=environment).get(database_name)\n        if not db:\n            return None\n\n        # Otherwise, get the URL from the database list\n        return db.get(\"api_endpoint\")\n\n    def get_api_endpoint(self):\n        return self.get_api_endpoint_static(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=self.api_endpoint,\n            database_name=self.database_name,\n        )\n\n    def get_keyspace(self):\n        keyspace = self.keyspace\n\n        if keyspace:\n            return keyspace.strip()\n\n        return None\n\n    def get_database_object(self, api_endpoint: str | None = None):\n        try:\n            client = DataAPIClient(token=self.token, environment=self.environment)\n\n            return client.get_database(\n                api_endpoint=api_endpoint or self.get_api_endpoint(),\n                token=self.token,\n                keyspace=self.get_keyspace(),\n            )\n        except Exception as e:\n            msg = f\"Error fetching database object: {e}\"\n            raise ValueError(msg) from e\n\n    def collection_data(self, collection_name: str, database: Database | None = None):\n        try:\n            if not database:\n                client = DataAPIClient(token=self.token, environment=self.environment)\n\n                database = client.get_database(\n                    api_endpoint=self.get_api_endpoint(),\n                    token=self.token,\n                    keyspace=self.get_keyspace(),\n                )\n\n            collection = database.get_collection(collection_name, keyspace=self.get_keyspace())\n\n            return collection.estimated_document_count()\n        except Exception as e:  # noqa: BLE001\n            self.log(f\"Error checking collection data: {e}\")\n\n            return None\n\n    def _initialize_database_options(self):\n        try:\n            return [\n                {\n                    \"name\": name,\n                    \"status\": info[\"status\"],\n                    \"collections\": info[\"collections\"],\n                    \"api_endpoint\": info[\"api_endpoint\"],\n                    \"icon\": \"data\",\n                }\n                for name, info in self.get_database_list().items()\n            ]\n        except Exception as e:\n            msg = f\"Error fetching database options: {e}\"\n            raise ValueError(msg) from e\n\n    @classmethod\n    def get_provider_icon(cls, collection: CollectionDescriptor | None = None, provider_name: str | None = None) -> str:\n        # Get the provider name from the collection\n        provider_name = provider_name or (\n            collection.options.vector.service.provider\n            if collection and collection.options and collection.options.vector and collection.options.vector.service\n            else None\n        )\n\n        # If there is no provider, use the vector store icon\n        if not provider_name or provider_name == \"bring your own\":\n            return \"vectorstores\"\n\n        # Special case for certain models\n        # TODO: Add more icons\n        if provider_name == \"nvidia\":\n            return \"NVIDIA\"\n        if provider_name == \"openai\":\n            return \"OpenAI\"\n\n        # Title case on the provider for the icon if no special case\n        return provider_name.title()\n\n    def _initialize_collection_options(self, api_endpoint: str | None = None):\n        # Nothing to generate if we don't have an API endpoint yet\n        api_endpoint = api_endpoint or self.get_api_endpoint()\n        if not api_endpoint:\n            return []\n\n        # Retrieve the database object\n        database = self.get_database_object(api_endpoint=api_endpoint)\n\n        # Get the list of collections\n        collection_list = list(database.list_collections(keyspace=self.get_keyspace()))\n\n        # Return the list of collections and metadata associated\n        return [\n            {\n                \"name\": col.name,\n                \"records\": self.collection_data(collection_name=col.name, database=database),\n                \"provider\": (\n                    col.options.vector.service.provider if col.options.vector and col.options.vector.service else None\n                ),\n                \"icon\": self.get_provider_icon(collection=col),\n                \"model\": (\n                    col.options.vector.service.model_name if col.options.vector and col.options.vector.service else None\n                ),\n            }\n            for col in collection_list\n        ]\n\n    def reset_provider_options(self, build_config: dict):\n        # Get the list of vectorize providers\n        vectorize_providers = self.get_vectorize_providers(\n            token=self.token,\n            environment=self.environment,\n            api_endpoint=build_config[\"api_endpoint\"][\"value\"],\n        )\n\n        # Append a special case for Bring your own\n        vectorize_providers[\"Bring your own\"] = [None, [\"Bring your own\"]]\n\n        # If the collection is set, allow user to see embedding options\n        build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_provider\"\n        ][\"options\"] = [\"Bring your own\", \"Nvidia\", *[key for key in vectorize_providers if key != \"Nvidia\"]]\n\n        # For all not Bring your own or Nvidia providers, add metadata saying configure in Astra DB Portal\n        provider_options = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_provider\"\n        ][\"options\"]\n\n        # Go over each possible provider and add metadata to configure in Astra DB Portal\n        for provider in provider_options:\n            # Skip Bring your own and Nvidia, automatically configured\n            if provider in [\"Bring your own\", \"Nvidia\"]:\n                build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                    \"embedding_generation_provider\"\n                ][\"options_metadata\"].append({\"icon\": self.get_provider_icon(provider_name=provider.lower())})\n                continue\n\n            # Add metadata to configure in Astra DB Portal\n            build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n                \"embedding_generation_provider\"\n            ][\"options_metadata\"].append({\" \": \"Configure in Astra DB Portal\"})\n\n        # And allow the user to see the models based on a selected provider\n        embedding_provider = build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_provider\"\n        ][\"value\"]\n\n        # Set the options for the embedding model based on the provider\n        build_config[\"collection_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\n            \"embedding_generation_model\"\n        ][\"options\"] = vectorize_providers.get(embedding_provider, [[], []])[1]\n\n        return build_config\n\n    def reset_collection_list(self, build_config: dict):\n        # Get the list of options we have based on the token provided\n        collection_options = self._initialize_collection_options(api_endpoint=build_config[\"api_endpoint\"][\"value\"])\n\n        # If we retrieved options based on the token, show the dropdown\n        build_config[\"collection_name\"][\"options\"] = [col[\"name\"] for col in collection_options]\n        build_config[\"collection_name\"][\"options_metadata\"] = [\n            {k: v for k, v in col.items() if k not in [\"name\"]} for col in collection_options\n        ]\n\n        # Reset the selected collection\n        if build_config[\"collection_name\"][\"value\"] not in build_config[\"collection_name\"][\"options\"]:\n            build_config[\"collection_name\"][\"value\"] = \"\"\n\n        # If we have a database, collection name should not be advanced\n        build_config[\"collection_name\"][\"advanced\"] = not build_config[\"database_name\"][\"value\"]\n\n        return build_config\n\n    def reset_database_list(self, build_config: dict):\n        # Get the list of options we have based on the token provided\n        database_options = self._initialize_database_options()\n\n        # If we retrieved options based on the token, show the dropdown\n        build_config[\"database_name\"][\"options\"] = [db[\"name\"] for db in database_options]\n        build_config[\"database_name\"][\"options_metadata\"] = [\n            {k: v for k, v in db.items() if k not in [\"name\"]} for db in database_options\n        ]\n\n        # Reset the selected database\n        if build_config[\"database_name\"][\"value\"] not in build_config[\"database_name\"][\"options\"]:\n            build_config[\"database_name\"][\"value\"] = \"\"\n            build_config[\"api_endpoint\"][\"value\"] = \"\"\n            build_config[\"collection_name\"][\"advanced\"] = True\n\n        # If we have a token, database name should not be advanced\n        build_config[\"database_name\"][\"advanced\"] = not build_config[\"token\"][\"value\"]\n\n        return build_config\n\n    def reset_build_config(self, build_config: dict):\n        # Reset the list of databases we have based on the token provided\n        build_config[\"database_name\"][\"options\"] = []\n        build_config[\"database_name\"][\"options_metadata\"] = []\n        build_config[\"database_name\"][\"value\"] = \"\"\n        build_config[\"database_name\"][\"advanced\"] = True\n        build_config[\"api_endpoint\"][\"value\"] = \"\"\n\n        # Reset the list of collections and metadata associated\n        build_config[\"collection_name\"][\"options\"] = []\n        build_config[\"collection_name\"][\"options_metadata\"] = []\n        build_config[\"collection_name\"][\"value\"] = \"\"\n        build_config[\"collection_name\"][\"advanced\"] = True\n\n        return build_config\n\n    async def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        # Callback for database creation\n        if field_name == \"database_name\" and isinstance(field_value, dict) and \"new_database_name\" in field_value:\n            try:\n                await self.create_database_api(\n                    new_database_name=field_value[\"new_database_name\"],\n                    token=self.token,\n                    keyspace=self.get_keyspace(),\n                    environment=self.environment,\n                    cloud_provider=field_value[\"cloud_provider\"],\n                    region=field_value[\"region\"],\n                )\n            except Exception as e:\n                msg = f\"Error creating database: {e}\"\n                raise ValueError(msg) from e\n\n            # Add the new database to the list of options\n            build_config[\"database_name\"][\"options\"] = build_config[\"database_name\"][\"options\"] + [\n                field_value[\"new_database_name\"]\n            ]\n            build_config[\"database_name\"][\"options_metadata\"] = build_config[\"database_name\"][\"options_metadata\"] + [\n                {\"status\": \"PENDING\"}\n            ]\n\n            return self.reset_collection_list(build_config)\n\n        # This is the callback required to update the list of regions for a cloud provider\n        if field_name == \"database_name\" and isinstance(field_value, dict) and \"new_database_name\" not in field_value:\n            cloud_provider = field_value[\"cloud_provider\"]\n            build_config[\"database_name\"][\"dialog_inputs\"][\"fields\"][\"data\"][\"node\"][\"template\"][\"region\"][\n                \"options\"\n            ] = self.map_cloud_providers()[cloud_provider][\"regions\"]\n\n            return build_config\n\n        # Callback for the creation of collections\n        if field_name == \"collection_name\" and isinstance(field_value, dict) and \"new_collection_name\" in field_value:\n            try:\n                # Get the dimension if its a BYO provider\n                dimension = (\n                    field_value[\"dimension\"]\n                    if field_value[\"embedding_generation_provider\"] == \"Bring your own\"\n                    else None\n                )\n\n                # Create the collection\n                await self.create_collection_api(\n                    new_collection_name=field_value[\"new_collection_name\"],\n                    token=self.token,\n                    api_endpoint=build_config[\"api_endpoint\"][\"value\"],\n                    environment=self.environment,\n                    keyspace=self.get_keyspace(),\n                    dimension=dimension,\n                    embedding_generation_provider=field_value[\"embedding_generation_provider\"],\n                    embedding_generation_model=field_value[\"embedding_generation_model\"],\n                )\n            except Exception as e:\n                msg = f\"Error creating collection: {e}\"\n                raise ValueError(msg) from e\n\n            # Add the new collection to the list of options\n            build_config[\"collection_name\"][\"value\"] = field_value[\"new_collection_name\"]\n            build_config[\"collection_name\"][\"options\"].append(field_value[\"new_collection_name\"])\n\n            # Get the provider and model for the new collection\n            generation_provider = field_value[\"embedding_generation_provider\"]\n            provider = generation_provider if generation_provider != \"Bring your own\" else None\n            generation_model = field_value[\"embedding_generation_model\"]\n            model = generation_model if generation_model and generation_model != \"Bring your own\" else None\n\n            # Set the embedding choice\n            build_config[\"embedding_choice\"][\"value\"] = \"Astra Vectorize\" if provider else \"Embedding Model\"\n            build_config[\"embedding_model\"][\"advanced\"] = bool(provider)\n\n            # Add the new collection to the list of options\n            icon = \"NVIDIA\" if provider == \"Nvidia\" else \"vectorstores\"\n            build_config[\"collection_name\"][\"options_metadata\"] = build_config[\"collection_name\"][\n                \"options_metadata\"\n            ] + [{\"records\": 0, \"provider\": provider, \"icon\": icon, \"model\": model}]\n\n            return build_config\n\n        # Callback to update the model list based on the embedding provider\n        if (\n            field_name == \"collection_name\"\n            and isinstance(field_value, dict)\n            and \"new_collection_name\" not in field_value\n        ):\n            return self.reset_provider_options(build_config)\n\n        # When the component first executes, this is the update refresh call\n        first_run = field_name == \"collection_name\" and not field_value and not build_config[\"database_name\"][\"options\"]\n\n        # If the token has not been provided, simply return the empty build config\n        if not self.token:\n            return self.reset_build_config(build_config)\n\n        # If this is the first execution of the component, reset and build database list\n        if first_run or field_name in [\"token\", \"environment\"]:\n            return self.reset_database_list(build_config)\n\n        # Refresh the collection name options\n        if field_name == \"database_name\" and not isinstance(field_value, dict):\n            # If missing, refresh the database options\n            if field_value not in build_config[\"database_name\"][\"options\"]:\n                build_config = await self.update_build_config(build_config, field_value=self.token, field_name=\"token\")\n                build_config[\"database_name\"][\"value\"] = \"\"\n            else:\n                # Find the position of the selected database to align with metadata\n                index_of_name = build_config[\"database_name\"][\"options\"].index(field_value)\n\n                # Initializing database condition\n                pending = build_config[\"database_name\"][\"options_metadata\"][index_of_name][\"status\"] == \"PENDING\"\n                if pending:\n                    return self.update_build_config(build_config, field_value=self.token, field_name=\"token\")\n\n                # Set the API endpoint based on the selected database\n                build_config[\"api_endpoint\"][\"value\"] = build_config[\"database_name\"][\"options_metadata\"][\n                    index_of_name\n                ][\"api_endpoint\"]\n\n                # Reset the provider options\n                build_config = self.reset_provider_options(build_config)\n\n            # Reset the list of collections we have based on the token provided\n            return self.reset_collection_list(build_config)\n\n        # Hide embedding model option if opriona_metadata provider is not null\n        if field_name == \"collection_name\" and not isinstance(field_value, dict):\n            # Assume we will be autodetecting the collection:\n            build_config[\"autodetect_collection\"][\"value\"] = True\n\n            # Reload the collection list\n            build_config = self.reset_collection_list(build_config)\n\n            # Set the options for collection name to be the field value if its a new collection\n            if field_value and field_value not in build_config[\"collection_name\"][\"options\"]:\n                # Add the new collection to the list of options\n                build_config[\"collection_name\"][\"options\"].append(field_value)\n                build_config[\"collection_name\"][\"options_metadata\"].append(\n                    {\"records\": 0, \"provider\": None, \"icon\": \"\", \"model\": None}\n                )\n\n                # Ensure that autodetect collection is set to False, since its a new collection\n                build_config[\"autodetect_collection\"][\"value\"] = False\n\n            # If nothing is selected, can't detect provider - return\n            if not field_value:\n                return build_config\n\n            # Find the position of the selected collection to align with metadata\n            index_of_name = build_config[\"collection_name\"][\"options\"].index(field_value)\n            value_of_provider = build_config[\"collection_name\"][\"options_metadata\"][index_of_name][\"provider\"]\n\n            # If we were able to determine the Vectorize provider, set it accordingly\n            if value_of_provider:\n                build_config[\"embedding_model\"][\"advanced\"] = True\n                build_config[\"embedding_choice\"][\"value\"] = \"Astra Vectorize\"\n            else:\n                build_config[\"embedding_model\"][\"advanced\"] = False\n                build_config[\"embedding_choice\"][\"value\"] = \"Embedding Model\"\n\n            return build_config\n\n        return build_config\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n        except ImportError as e:\n            msg = (\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n            raise ImportError(msg) from e\n\n        # Get the embedding model and additional params\n        embedding_params = (\n            {\"embedding\": self.embedding_model}\n            if self.embedding_model and self.embedding_choice == \"Embedding Model\"\n            else {}\n        )\n\n        # Get the additional parameters\n        additional_params = self.astradb_vectorstore_kwargs or {}\n\n        # Get Langflow version and platform information\n        __version__ = get_version_info()[\"version\"]\n        langflow_prefix = \"\"\n        # if os.getenv(\"AWS_EXECUTION_ENV\") == \"AWS_ECS_FARGATE\":  # TODO: More precise way of detecting\n        #     langflow_prefix = \"ds-\"\n\n        # Get the database object\n        database = self.get_database_object()\n        autodetect = self.collection_name in database.list_collection_names() and self.autodetect_collection\n\n        # Bundle up the auto-detect parameters\n        autodetect_params = {\n            \"autodetect_collection\": autodetect,\n            \"content_field\": (\n                self.content_field\n                if self.content_field and embedding_params\n                else (\n                    \"page_content\"\n                    if embedding_params\n                    and self.collection_data(collection_name=self.collection_name, database=database) == 0\n                    else None\n                )\n            ),\n            \"ignore_invalid_documents\": self.ignore_invalid_documents,\n        }\n\n        # Attempt to build the Vector Store object\n        try:\n            vector_store = AstraDBVectorStore(\n                # Astra DB Authentication Parameters\n                token=self.token,\n                api_endpoint=database.api_endpoint,\n                namespace=database.keyspace,\n                collection_name=self.collection_name,\n                environment=self.environment,\n                # Astra DB Usage Tracking Parameters\n                ext_callers=[(f\"{langflow_prefix}langflow\", __version__)],\n                # Astra DB Vector Store Parameters\n                **autodetect_params,\n                **embedding_params,\n                **additional_params,\n            )\n        except Exception as e:\n            msg = f\"Error initializing AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        # Add documents to the vector store\n        self._add_documents_to_vector_store(vector_store)\n\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store) -> None:\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                msg = \"Vector Store Inputs must be Data objects.\"\n                raise TypeError(msg)\n\n        if documents and self.deletion_field:\n            self.log(f\"Deleting documents where {self.deletion_field}\")\n            try:\n                database = self.get_database_object()\n                collection = database.get_collection(self.collection_name, keyspace=database.keyspace)\n                delete_values = list({doc.metadata[self.deletion_field] for doc in documents})\n                self.log(f\"Deleting documents where {self.deletion_field} matches {delete_values}.\")\n                collection.delete_many({f\"metadata.{self.deletion_field}\": {\"$in\": delete_values}})\n            except Exception as e:\n                msg = f\"Error deleting documents from AstraDBVectorStore based on '{self.deletion_field}': {e}\"\n                raise ValueError(msg) from e\n\n        if documents:\n            self.log(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                msg = f\"Error adding documents to AstraDBVectorStore: {e}\"\n                raise ValueError(msg) from e\n        else:\n            self.log(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self) -> str:\n        search_type_mapping = {\n            \"Similarity with score threshold\": \"similarity_score_threshold\",\n            \"MMR (Max Marginal Relevance)\": \"mmr\",\n        }\n\n        return search_type_mapping.get(self.search_type, \"similarity\")\n\n    def _build_search_args(self):\n        query = self.search_query if isinstance(self.search_query, str) and self.search_query.strip() else None\n\n        if query:\n            args = {\n                \"query\": query,\n                \"search_type\": self._map_search_type(),\n                \"k\": self.number_of_results,\n                \"score_threshold\": self.search_score_threshold,\n            }\n        elif self.advanced_search_filter:\n            args = {\n                \"n\": self.number_of_results,\n            }\n        else:\n            return {}\n\n        filter_arg = self.advanced_search_filter or {}\n        if filter_arg:\n            args[\"filter\"] = filter_arg\n\n        return args\n\n    def search_documents(self, vector_store=None) -> list[Data]:\n        vector_store = vector_store or self.build_vector_store()\n\n        self.log(f\"Search input: {self.search_query}\")\n        self.log(f\"Search type: {self.search_type}\")\n        self.log(f\"Number of results: {self.number_of_results}\")\n\n        try:\n            search_args = self._build_search_args()\n        except Exception as e:\n            msg = f\"Error in AstraDBVectorStore._build_search_args: {e}\"\n            raise ValueError(msg) from e\n\n        if not search_args:\n            self.log(\"No search input or filters provided. Skipping search.\")\n            return []\n\n        docs = []\n        search_method = \"search\" if \"query\" in search_args else \"metadata_search\"\n\n        try:\n            self.log(f\"Calling vector_store.{search_method} with args: {search_args}\")\n            docs = getattr(vector_store, search_method)(**search_args)\n        except Exception as e:\n            msg = f\"Error performing {search_method} in AstraDBVectorStore: {e}\"\n            raise ValueError(msg) from e\n\n        self.log(f\"Retrieved documents: {len(docs)}\")\n\n        data = docs_to_data(docs)\n        self.log(f\"Converted documents to data: {len(data)}\")\n        self.status = data\n\n        return data\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "collection_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [],
                "options_metadata": [],
                "combobox": true,
                "dialog_inputs": {
                  "functionality": "create",
                  "fields": {
                    "data": {
                      "node": {
                        "name": "create_collection",
                        "description": "",
                        "display_name": "Create new collection",
                        "field_order": [
                          "new_collection_name",
                          "embedding_generation_provider",
                          "embedding_generation_model",
                          "dimension"
                        ],
                        "template": {
                          "new_collection_name": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "load_from_db": false,
                            "list": false,
                            "list_add_label": "Add More",
                            "required": true,
                            "placeholder": "",
                            "show": true,
                            "name": "new_collection_name",
                            "value": "",
                            "display_name": "Name",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Name of the new collection to create in Astra DB.",
                            "title_case": false,
                            "type": "str",
                            "_input_type": "StrInput"
                          },
                          "embedding_generation_provider": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "options": [
                              "Bring your own",
                              "Nvidia"
                            ],
                            "options_metadata": [],
                            "combobox": false,
                            "dialog_inputs": {},
                            "required": true,
                            "placeholder": "",
                            "show": true,
                            "name": "embedding_generation_provider",
                            "value": "",
                            "display_name": "Embedding generation method",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Provider to use for generating embeddings.",
                            "real_time_refresh": true,
                            "title_case": false,
                            "type": "str",
                            "_input_type": "DropdownInput"
                          },
                          "embedding_generation_model": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "options": [],
                            "options_metadata": [],
                            "combobox": false,
                            "dialog_inputs": {},
                            "required": true,
                            "placeholder": "",
                            "show": true,
                            "name": "embedding_generation_model",
                            "value": "",
                            "display_name": "Embedding model",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Model to use for generating embeddings.",
                            "title_case": false,
                            "type": "str",
                            "_input_type": "DropdownInput"
                          },
                          "dimension": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "list": false,
                            "list_add_label": "Add More",
                            "required": false,
                            "placeholder": "",
                            "show": true,
                            "name": "dimension",
                            "value": 1024,
                            "display_name": "Dimensions (Required only for `Bring your own`)",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Dimensions of the embeddings to generate.",
                            "title_case": false,
                            "type": "int",
                            "_input_type": "IntInput"
                          }
                        }
                      }
                    }
                  }
                },
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "collection_name",
                "value": "veo_omsk",
                "display_name": "Collection",
                "advanced": true,
                "dynamic": false,
                "info": "The name of the collection within Astra DB where the vectors will be stored.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "content_field": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "content_field",
                "value": "",
                "display_name": "Content Field",
                "advanced": true,
                "dynamic": false,
                "info": "Field to use as the text content field for the vector store.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "database_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [],
                "options_metadata": [],
                "combobox": true,
                "dialog_inputs": {
                  "functionality": "create",
                  "fields": {
                    "data": {
                      "node": {
                        "name": "create_database",
                        "description": "",
                        "display_name": "Create new database",
                        "field_order": [
                          "new_database_name",
                          "cloud_provider",
                          "region"
                        ],
                        "template": {
                          "new_database_name": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "load_from_db": false,
                            "list": false,
                            "list_add_label": "Add More",
                            "required": true,
                            "placeholder": "",
                            "show": true,
                            "name": "new_database_name",
                            "value": "",
                            "display_name": "Name",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Name of the new database to create in Astra DB.",
                            "title_case": false,
                            "type": "str",
                            "_input_type": "StrInput"
                          },
                          "cloud_provider": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "options": [
                              "Amazon Web Services",
                              "Google Cloud Platform",
                              "Microsoft Azure"
                            ],
                            "options_metadata": [],
                            "combobox": false,
                            "dialog_inputs": {},
                            "required": true,
                            "placeholder": "",
                            "show": true,
                            "name": "cloud_provider",
                            "value": "",
                            "display_name": "Cloud provider",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Cloud provider for the new database.",
                            "real_time_refresh": true,
                            "title_case": false,
                            "type": "str",
                            "_input_type": "DropdownInput"
                          },
                          "region": {
                            "tool_mode": false,
                            "trace_as_metadata": true,
                            "options": [],
                            "options_metadata": [],
                            "combobox": false,
                            "dialog_inputs": {},
                            "required": true,
                            "placeholder": "",
                            "show": true,
                            "name": "region",
                            "value": "",
                            "display_name": "Region",
                            "advanced": false,
                            "dynamic": false,
                            "info": "Region for the new database.",
                            "title_case": false,
                            "type": "str",
                            "_input_type": "DropdownInput"
                          }
                        }
                      }
                    }
                  }
                },
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "database_name",
                "value": "",
                "display_name": "Database",
                "advanced": false,
                "dynamic": false,
                "info": "The Database name for the Astra DB instance.",
                "real_time_refresh": true,
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "deletion_field": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deletion_field",
                "value": "",
                "display_name": "Deletion Based On Field",
                "advanced": true,
                "dynamic": false,
                "info": "When this parameter is provided, documents in the target collection with metadata field values matching the input metadata field value will be deleted before new data is loaded.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "embedding_choice": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Embedding Model",
                  "Astra Vectorize"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_choice",
                "value": "Embedding Model",
                "display_name": "Embedding Model or Astra Vectorize",
                "advanced": true,
                "dynamic": false,
                "info": "Choose an embedding model or use Astra Vectorize.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "environment": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "environment",
                "value": "",
                "display_name": "Environment",
                "advanced": true,
                "dynamic": false,
                "info": "The environment for the Astra DB API Endpoint.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "ignore_invalid_documents": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ignore_invalid_documents",
                "value": false,
                "display_name": "Ignore Invalid Documents",
                "advanced": true,
                "dynamic": false,
                "info": "Boolean flag to determine whether to ignore invalid documents at runtime.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "keyspace": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "keyspace",
                "value": "",
                "display_name": "Keyspace",
                "advanced": true,
                "dynamic": false,
                "info": "Optional keyspace within Astra DB to use for the collection.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Search Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of search results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "search_query": {
                "tool_mode": true,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "search_score_threshold": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_score_threshold",
                "value": 0,
                "display_name": "Search Score Threshold",
                "advanced": true,
                "dynamic": false,
                "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "search_type": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Similarity",
                  "Similarity with score threshold",
                  "MMR (Max Marginal Relevance)"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_type",
                "value": "Similarity",
                "display_name": "Search Type",
                "advanced": true,
                "dynamic": false,
                "info": "Search type to use",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "should_cache_vector_store": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_cache_vector_store",
                "value": true,
                "display_name": "Cache Vector Store",
                "advanced": true,
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "token": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "token",
                "value": "",
                "display_name": "Astra DB Application Token",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Authentication token for accessing Astra DB.",
                "real_time_refresh": true,
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Ingest and search documents in Astra DB",
            "icon": "AstraDB",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "Astra DB",
            "documentation": "https://docs.datastax.com/en/langflow/astra-components.html",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "hidden": null,
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "collection_name",
                  "database_name",
                  "token"
                ],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "hidden": null,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "token",
              "environment",
              "database_name",
              "api_endpoint",
              "collection_name",
              "keyspace",
              "embedding_choice",
              "embedding_model",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "number_of_results",
              "search_type",
              "search_score_threshold",
              "advanced_search_filter",
              "autodetect_collection",
              "content_field",
              "deletion_field",
              "ignore_invalid_documents",
              "astradb_vectorstore_kwargs"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "AstraDB"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 531
        }
      },
      {
        "id": "LMStudioModel-z64zV",
        "type": "genericNode",
        "position": {
          "x": 2526.338720090813,
          "y": 1273.6613598008914
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "LM Studio API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The LM Studio API Key to use for LM Studio.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_url": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "http://localhost:1234/v1",
                "display_name": "Base URL",
                "advanced": false,
                "dynamic": false,
                "info": "Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom langchain_openai import ChatOpenAI\nfrom typing_extensions import override\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\n\n\nclass LMStudioModelComponent(LCModelComponent):\n    display_name = \"LM Studio\"\n    description = \"Generate text using LM Studio Local LLMs.\"\n    icon = \"LMStudio\"\n    name = \"LMStudioModel\"\n\n    @override\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"model_name\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = await self.get_variables(base_url_value, field_name)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:1234/v1\"\n            build_config[\"model_name\"][\"options\"] = await self.get_model(base_url_value)\n\n        return build_config\n\n    @staticmethod\n    async def get_model(base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/v1/models\")\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"id\"] for model in data.get(\"data\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure the LM Studio server is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            refresh_button=True,\n        ),\n        StrInput(\n            name=\"base_url\",\n            display_name=\"Base URL\",\n            advanced=False,\n            info=\"Endpoint of the LM Studio API. Defaults to 'http://localhost:1234/v1' if not specified.\",\n            value=\"http://localhost:1234/v1\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LM Studio API Key\",\n            info=\"The LM Studio API Key to use for LM Studio.\",\n            advanced=True,\n            value=\"LMSTUDIO_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        lmstudio_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        base_url = self.base_url or \"http://localhost:1234/v1\"\n        seed = self.seed\n\n        return ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=base_url,\n            api_key=lmstudio_api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an LM Studio exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": 1024,
                "display_name": "Max Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-nomic-embed-text-v1.5-embedding",
                  "text-embedding-nomic-embed-text-v1.5",
                  "deepseek-r1-distill-qwen-14b",
                  "hermes-3-llama-3.1-8b",
                  "deepseek-r1-distill-llama-8b",
                  "mistral-nemo-instruct-2407",
                  "deepseek-r1-distill-qwen-7b"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "deepseek-r1-distill-qwen-14b",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "seed": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 42,
                "display_name": "Seed",
                "advanced": false,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.11,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using LM Studio Local LLMs.",
            "icon": "LMStudio",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "LM Studio",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Message",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "hidden": null,
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "model_name",
              "base_url",
              "api_key",
              "temperature",
              "seed"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "models",
            "key": "LMStudioModel",
            "score": 0.004118976729312807,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "LMStudioModel",
          "id": "LMStudioModel-z64zV"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 810
        }
      },
      {
        "id": "LMStudioEmbeddingsComponent-5YUQf",
        "type": "genericNode",
        "position": {
          "x": 816.6602134599385,
          "y": 1336.7967895417394
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "LM Studio API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "base_url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "base_url",
                "value": "http://localhost:1234/v1",
                "display_name": "LM Studio Base URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\nfrom urllib.parse import urljoin\n\nimport httpx\nfrom typing_extensions import override\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.field_typing import Embeddings\nfrom langflow.inputs.inputs import DropdownInput, SecretStrInput\nfrom langflow.io import FloatInput, MessageTextInput\n\n\nclass LMStudioEmbeddingsComponent(LCEmbeddingsModel):\n    display_name: str = \"LM Studio Embeddings\"\n    description: str = \"Generate embeddings using LM Studio.\"\n    icon = \"LMStudio\"\n\n    @override\n    async def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None):\n        if field_name == \"model\":\n            base_url_dict = build_config.get(\"base_url\", {})\n            base_url_load_from_db = base_url_dict.get(\"load_from_db\", False)\n            base_url_value = base_url_dict.get(\"value\")\n            if base_url_load_from_db:\n                base_url_value = await self.get_variables(base_url_value, field_name)\n            elif not base_url_value:\n                base_url_value = \"http://localhost:1234/v1\"\n            build_config[\"model\"][\"options\"] = await self.get_model(base_url_value)\n\n        return build_config\n\n    @staticmethod\n    async def get_model(base_url_value: str) -> list[str]:\n        try:\n            url = urljoin(base_url_value, \"/v1/models\")\n            async with httpx.AsyncClient() as client:\n                response = await client.get(url)\n                response.raise_for_status()\n                data = response.json()\n\n                return [model[\"id\"] for model in data.get(\"data\", [])]\n        except Exception as e:\n            msg = \"Could not retrieve models. Please, make sure the LM Studio server is running.\"\n            raise ValueError(msg) from e\n\n    inputs = [\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            refresh_button=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"base_url\",\n            display_name=\"LM Studio Base URL\",\n            refresh_button=True,\n            value=\"http://localhost:1234/v1\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"LM Studio API Key\",\n            advanced=True,\n            value=\"LMSTUDIO_API_KEY\",\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Model Temperature\",\n            value=0.1,\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        try:\n            from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n        except ImportError as e:\n            msg = \"Please install langchain-nvidia-ai-endpoints to use LM Studio Embeddings.\"\n            raise ImportError(msg) from e\n        try:\n            output = NVIDIAEmbeddings(\n                model=self.model,\n                base_url=self.base_url,\n                temperature=self.temperature,\n                nvidia_api_key=self.api_key,\n            )\n        except Exception as e:\n            msg = f\"Could not connect to LM Studio API. Error: {e}\"\n            raise ValueError(msg) from e\n        return output\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-nomic-embed-text-v1.5-embedding",
                  "text-embedding-nomic-embed-text-v1.5",
                  "deepseek-r1-distill-qwen-14b",
                  "hermes-3-llama-3.1-8b",
                  "deepseek-r1-distill-llama-8b",
                  "mistral-nemo-instruct-2407",
                  "deepseek-r1-distill-qwen-7b"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-nomic-embed-text-v1.5-embedding",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "temperature": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Model Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate embeddings using LM Studio.",
            "icon": "LMStudio",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "LM Studio Embeddings",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "hidden": null,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "base_url",
                  "model"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "model",
              "base_url",
              "api_key",
              "temperature"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "LMStudioEmbeddingsComponent",
          "id": "LMStudioEmbeddingsComponent-5YUQf"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 307
        },
        "dragging": false
      },
      {
        "id": "TextInput-JvrFp",
        "type": "genericNode",
        "position": {
          "x": 15,
          "y": 503.84070956968253
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "TextInput",
          "id": "TextInput-JvrFp"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 229
        }
      },
      {
        "id": "MessagetoData-R0qlr",
        "type": "genericNode",
        "position": {
          "x": 392.63535206131417,
          "y": 514.8704101878529
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass MessageToDataComponent(Component):\n    display_name = \"Message to Data\"\n    description = \"Convert a Message object to a Data object\"\n    icon = \"message-square-share\"\n    beta = True\n    name = \"MessagetoData\"\n\n    inputs = [\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object to convert to a Data object\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"convert_message_to_data\"),\n    ]\n\n    def convert_message_to_data(self) -> Data:\n        if isinstance(self.message, Message):\n            # Convert Message to Data\n            return Data(data=self.message.data)\n\n        msg = \"Error converting Message to Data: Input must be a Message object\"\n        logger.opt(exception=True).debug(msg)\n        self.status = msg\n        return Data(data={\"error\": msg})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object to convert to a Data object",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Convert a Message object to a Data object",
            "icon": "message-square-share",
            "base_classes": [
              "Data"
            ],
            "display_name": "Message to Data",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "convert_message_to_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "message"
            ],
            "beta": true,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.4.post1"
          },
          "showNode": true,
          "type": "MessagetoData",
          "id": "MessagetoData-R0qlr"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 229
        }
      },
      {
        "id": "Memory-mSoi2",
        "type": "genericNode",
        "position": {
          "x": 1702.440522985537,
          "y": 1470.8437491796697
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": false,
                "input_types": [
                  "Memory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs import HandleInput\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import aget_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Message History\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"Memory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Message\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n    ]\n\n    async def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = await self.memory.aget_messages()\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = await aget_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    async def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, await self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "n_messages": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": false,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "order": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Retrieves stored chat messages from Langflow tables or an external memory.",
            "icon": "message-square-more",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Message History",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "messages",
                "display_name": "Data",
                "method": "retrieve_messages",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "messages_text",
                "display_name": "Message",
                "method": "retrieve_messages_as_text",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "Memory",
          "id": "Memory-mSoi2"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 341
        },
        "dragging": false
      },
      {
        "id": "Prompt-EmebA",
        "type": "genericNode",
        "position": {
          "x": 2114.058082281999,
          "y": 1916.028296948019
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "Ты — АВОКС (AVOX), цифровой ассистент питомника \"Омская Дружина\".  \n\nТы наблюдаешь за диалогом клиента и Ольги Владимировны (владельца питомника) в официальной группе ВКонтакте (VK).  \n**Клиент может не знать, что ты анализируешь диалог.**  \n\n## Твои задачи:\n0. Предоставлять актуальную информацию о питомнике\n1. **Определи, требуется ли помощь ассистента.**  \n2. **Выясни, кому адресован вопрос:**  \n   - Если клиент обращается к АВОКСУ, ответь кратко и по делу.  \n   - Если к Ольге Владимировне — **ответь системным сигналом `*wait*`** (или предложи воспользоваться цифровым ассистентом)\n   - Если вопрос общий, ненавязчиво предложи помощь. \n   - При первом обращении. Представься, поясни кто ты и **предупреди, что можешь содержать неточности!**\n   - Спроси хочет ли клиент воспользоваться цифровым ассистентом! \n3. **Не повторяйся, отвечай кратко и вежливо на русском языке (кириллица, цифры, иногда смайлики).**  \n4. **Определи рассматривает ли клиент покупку щенка:** \n5. **Собери критерии покупки щенка:**  \n   - Пол: мальчик (кобель) / девочка (сука).  \n   - Окрас.  \n   - Условия содержания: квартира / частный дом.  \n   - Цель: домашний любимец, работа, разведение.  \n   - Родители (необязательный критерий, если уже понятно).  \n6. **Определи доступность щенков согласно критериям:**  \n   - Если щенков **нет**, предупреди клиента.  \n   - Если щенки есть, **задай только один уточняющий вопрос** (если нужно).  \n   - Предложи рассмотреть текущих щенков или\n7. **Если большинство критериев известны - подведи итог.**  \n   - Например: \"Я резюмирую! Вам нужен …\" или \"Я передам Ольге Владимировне, что вам требуется…\".  \n8. **Если разговор зациклился - вежливо подведи итог и передай диалог Ольге Владимировне.**  \n\n## Важная информация:\n- Клиент мог уже забронировать/купить щенка и просто уточняет информацию. \n- АВОКС **не умеет присылать фото**, это делает Ольга.  \n- Бронь: 5000 р. переводом по номеру телефона.  \n- Полная оплата — перед отправкой.  \n- Щенки отдаются **только после прививок** (прививка после 2 месяцев, забирать через 14 дней после неё).  \n- \"Сука\" = \"девочка\" (это не ругательство).  \n- \"Кобель\" = \"мальчик\" (может быть написано с ошибкой).  \n- Восточноевропейская овчарка - используй сокращение: ВЕО\n- Овчары - неправильно написание, правильно \"Овчарки\"\n\n## **Важно для АВОКС:**  \n- **Не копируй текст из `<data>`.** Передавай суть кратко.  \n- **Не копируй текст из истории диалога.**  Используй историю для понимания контекста и подведения итогов.\n- **Отвечай вежливо, логично и по делу.**  \n- **Если диалог дошел до логического конца или сообщение явно адресовано Ольге, ответь `*wait*`.** (могут быть исключения)  \n-  **Ты умеешь точно рассчитывать возраст щенков в днях**. Используй формат: \"2 месяца и 10 дней\", \"1 месяц и 15 дней\", \"Примерно 3 месяца\"\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-EmebA"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 255
        },
        "dragging": false
      },
      {
        "id": "FAISS-SD53M",
        "type": "genericNode",
        "position": {
          "x": 1295.283021154378,
          "y": 545.9982925108992
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "embedding": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding",
                "value": "",
                "display_name": "Embedding",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "ingest_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ingest_data",
                "value": "",
                "display_name": "Ingest Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "allow_dangerous_deserialization": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "allow_dangerous_deserialization",
                "value": true,
                "display_name": "Allow Dangerous Deserialization",
                "advanced": true,
                "dynamic": false,
                "info": "Set to True to allow loading pickle files from untrusted sources.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_community.vectorstores import FAISS\r\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\r\nfrom langflow.helpers.data import docs_to_data\r\nfrom langflow.io import BoolInput, HandleInput, IntInput, StrInput, Output\r\nfrom langflow.schema import Data\r\nimport os\r\n\r\n\r\nclass FaissVectorStoreComponent(LCVectorStoreComponent):\r\n    \"\"\"FAISS Vector Store with conditional update logic.\"\"\"\r\n\r\n    display_name: str = \"FAISS\"\r\n    description: str = \"FAISS Vector Store with conditional indexing\"\r\n    name = \"FAISS\"\r\n    icon = \"FAISS\"\r\n\r\n    inputs = [\r\n        StrInput(name=\"index_name\", display_name=\"Index Name\", value=\"langflow_index\"),\r\n        StrInput(name=\"persist_directory\", display_name=\"Persist Directory\", info=\"Path to save the FAISS index.\"),\r\n        IntInput(name=\"vector_dim\", display_name=\"Vector Dimension\", info=\"Dimension of embedding vectors.\", value=768),\r\n        *LCVectorStoreComponent.inputs,\r\n        BoolInput(name=\"allow_dangerous_deserialization\", display_name=\"Allow Dangerous Deserialization\",\r\n                  info=\"Set to True to allow loading pickle files from untrusted sources.\", advanced=True, value=True),\r\n        HandleInput(name=\"embedding\", display_name=\"Embedding\", input_types=[\"Embeddings\"]),\r\n        IntInput(name=\"number_of_results\", display_name=\"Number of Results\", info=\"Number of results to return.\",\r\n                 advanced=True, value=4),\r\n        BoolInput(name=\"force_rebuild\", display_name=\"Force Rebuild\", info=\"If set to True, rebuilds the FAISS index.\",\r\n                  value=False),\r\n    ]\r\n\r\n    outputs = LCVectorStoreComponent.outputs + [\r\n        Output(display_name=\"Vector Store\", name=\"vector_store\", method=\"build_vector_store\")\r\n    ]\r\n\r\n    @check_cached_vector_store\r\n    def build_vector_store(self) -> FAISS:\r\n        \"\"\"Conditional index building with search-aware updates\"\"\"\r\n        if not self.persist_directory:\r\n            raise ValueError(\"Persist directory is required\")\r\n\r\n        path = self.resolve_path(self.persist_directory)\r\n        os.makedirs(path, exist_ok=True)\r\n        index_path = os.path.join(path, f\"{self.index_name}.faiss\")\r\n\r\n        # Existing index handling\r\n        if os.path.exists(index_path) and not self.force_rebuild:\r\n            vector_store = FAISS.load_local(\r\n                folder_path=path,\r\n                embeddings=self.embedding,\r\n                index_name=self.index_name,\r\n                allow_dangerous_deserialization=self.allow_dangerous_deserialization\r\n            )\r\n            \r\n            # Update only when no search query present\r\n            if self.ingest_data and not self.search_query.strip():\r\n                self._update_index(vector_store, path)\r\n            \r\n            return vector_store\r\n\r\n        # New index creation (required for search if missing)\r\n        return self._create_new_index(path)\r\n\r\n    def _update_index(self, vector_store: FAISS, path: str):\r\n        \"\"\"Update index with new documents\"\"\"\r\n        docs = [d.to_lc_document() if isinstance(d, Data) else d for d in self.ingest_data]\r\n        vector_store.add_documents(docs)\r\n        vector_store.save_local(path, self.index_name)\r\n        self.log(f\"Index updated with {len(docs)} new documents\")\r\n\r\n    def _create_new_index(self, path: str) -> FAISS:\r\n        \"\"\"Create new index from scratch\"\"\"\r\n        if not self.ingest_data:\r\n            raise ValueError(\"No data provided for index creation\")\r\n\r\n        docs = [d.to_lc_document() if isinstance(d, Data) else d for d in self.ingest_data]\r\n        vector_store = FAISS.from_documents(docs, self.embedding)\r\n        vector_store.save_local(path, self.index_name)\r\n        self.log(\"New FAISS index created\")\r\n        return vector_store\r\n\r\n    def search_documents(self) -> list[Data]:\r\n        \"\"\"Search-only execution flow\"\"\"\r\n        if not self.search_query.strip():\r\n            return []\r\n\r\n        vector_store = self.build_vector_store()\r\n        docs = vector_store.similarity_search(\r\n            query=self.search_query,\r\n            k=self.number_of_results\r\n        )\r\n        return docs_to_data(docs)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "force_rebuild": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "force_rebuild",
                "value": false,
                "display_name": "Force Rebuild",
                "advanced": false,
                "dynamic": false,
                "info": "If set to True, rebuilds the FAISS index.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "index_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "index_name",
                "value": "veoomsk_index",
                "display_name": "Index Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "number_of_results": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_results",
                "value": 4,
                "display_name": "Number of Results",
                "advanced": true,
                "dynamic": false,
                "info": "Number of results to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "persist_directory": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "persist_directory",
                "value": "./faiss/",
                "display_name": "Persist Directory",
                "advanced": false,
                "dynamic": false,
                "info": "Path to save the FAISS index.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "search_query": {
                "tool_mode": true,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "search_query",
                "value": "",
                "display_name": "Search Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "should_cache_vector_store": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_cache_vector_store",
                "value": true,
                "display_name": "Cache Vector Store",
                "advanced": true,
                "dynamic": false,
                "info": "If True, the vector store will be cached for the current build of the component. This is useful for components that have multiple output methods and want to share the same vector store.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "vector_dim": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "vector_dim",
                "value": 768,
                "display_name": "Vector Dimension",
                "advanced": false,
                "dynamic": false,
                "info": "Dimension of embedding vectors.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "FAISS Vector Store with conditional indexing",
            "icon": "FAISS",
            "base_classes": [
              "Data",
              "DataFrame",
              "FAISS"
            ],
            "display_name": "FAISS",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "search_results",
                "hidden": null,
                "display_name": "Search Results",
                "method": "search_documents",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "hidden": null,
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "FAISS"
                ],
                "selected": "FAISS",
                "name": "vector_store",
                "hidden": null,
                "display_name": "Vector Store",
                "method": "build_vector_store",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "index_name",
              "persist_directory",
              "vector_dim",
              "ingest_data",
              "search_query",
              "should_cache_vector_store",
              "allow_dangerous_deserialization",
              "embedding",
              "number_of_results",
              "force_rebuild"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "FAISS",
          "id": "FAISS-SD53M"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 705
        },
        "dragging": false
      },
      {
        "id": "URL-h47Jf",
        "type": "genericNode",
        "position": {
          "x": 386.5119255292118,
          "y": 45
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\n\nfrom langchain_community.document_loaders import AsyncHtmlLoader, WebBaseLoader\n\nfrom langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\n\n\nclass URLComponent(Component):\n    display_name = \"URL\"\n    description = \"Load and retrive data from specified URLs.\"\n    icon = \"layout-template\"\n    name = \"URL\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=\"Output Format. Use 'Text' to extract the text from the HTML or 'Raw HTML' for the raw HTML content.\",\n            options=[\"Text\", \"Raw HTML\"],\n            value=\"Text\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Message\", name=\"text\", method=\"fetch_content_text\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def ensure_url(self, string: str) -> str:\n        \"\"\"Ensures the given string is a URL by adding 'http://' if it doesn't start with 'http://' or 'https://'.\n\n        Raises an error if the string is not a valid URL.\n\n        Parameters:\n            string (str): The string to be checked and possibly modified.\n\n        Returns:\n            str: The modified string that is ensured to be a URL.\n\n        Raises:\n            ValueError: If the string is not a valid URL.\n        \"\"\"\n        if not string.startswith((\"http://\", \"https://\")):\n            string = \"http://\" + string\n\n        # Basic URL validation regex\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\"  # optional protocol\n            r\"(www\\.)?\"  # optional www\n            r\"([a-zA-Z0-9.-]+)\"  # domain\n            r\"(\\.[a-zA-Z]{2,})?\"  # top-level domain\n            r\"(:\\d+)?\"  # optional port\n            r\"(\\/[^\\s]*)?$\",  # optional path\n            re.IGNORECASE,\n        )\n\n        if not url_regex.match(string):\n            msg = f\"Invalid URL: {string}\"\n            raise ValueError(msg)\n\n        return string\n\n    def fetch_content(self) -> list[Data]:\n        urls = [self.ensure_url(url.strip()) for url in self.urls if url.strip()]\n        if self.format == \"Raw HTML\":\n            loader = AsyncHtmlLoader(web_path=urls, encoding=\"utf-8\")\n        else:\n            loader = WebBaseLoader(web_paths=urls, encoding=\"utf-8\")\n        docs = loader.load()\n        data = [Data(text=doc.page_content, **doc.metadata) for doc in docs]\n        self.status = data\n        return data\n\n    def fetch_content_text(self) -> Message:\n        data = self.fetch_content()\n\n        result_string = data_to_text(\"{text}\", data)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.fetch_content())\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "format": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Text",
                  "Raw HTML"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "format",
                "value": "Text",
                "display_name": "Output Format",
                "advanced": false,
                "dynamic": false,
                "info": "Output Format. Use 'Text' to extract the text from the HTML or 'Raw HTML' for the raw HTML content.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "urls": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": true,
                "list_add_label": "Add URL",
                "required": false,
                "placeholder": "Enter a URL...",
                "show": true,
                "name": "urls",
                "value": [
                  "https://veo55.ru/"
                ],
                "display_name": "URLs",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Load and retrive data from specified URLs.",
            "icon": "layout-template",
            "base_classes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "display_name": "URL",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "fetch_content",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "fetch_content_text",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "urls",
              "format"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "URL",
          "id": "URL-h47Jf"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 415
        }
      },
      {
        "id": "ChatOutput-h1uNY",
        "type": "genericNode",
        "position": {
          "x": 3741.424885916053,
          "y": 1691.5148871168763
        },
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Chat Output",
          "id": "ChatOutput-h1uNY",
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "АВОКС",
                "display_name": "Sender Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 274
        },
        "dragging": false
      },
      {
        "id": "ExtractThinkComponent-9uWtd",
        "type": "genericNode",
        "position": {
          "x": 2886.314325225622,
          "y": 1668.887603427097
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import re\r\nfrom langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass ExtractThinkComponent(Component):\r\n    display_name = \"Extract Think Component\"\r\n    description = \"Extracts content inside specified tags and text after the tag.\"\r\n    documentation = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"filter\"\r\n    name = \"ExtractThinkComponent\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input Message\",\r\n            info=\"Message containing the custom tag\",\r\n            value=\"<think>Example</think> This is after.\",\r\n            tool_mode=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"tag_name\",\r\n            display_name=\"Think tag Name\",\r\n            info=\"The name of the tag to extract\",\r\n            value=\"think\",\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted Data\", name=\"output\", method=\"build_output\"),\r\n    ]\r\n\r\n    def build_output(self) -> Data:\r\n        tag = self.tag_name.strip()\r\n        pattern = fr\"<{tag}>(.*?)</{tag}>(.*)\"\r\n        match = re.search(pattern, self.input_value, re.DOTALL)\r\n        \r\n        think_content = match.group(1).strip() if match else \"\"\r\n        message_content = match.group(2).strip() if match else self.input_value\r\n        \r\n        data = Data(data={\"think\": think_content, \"message\": message_content}, text_key=\"message\", default_value=None)\r\n        self.status = data\r\n        return data\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message containing the custom tag",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "tag_name": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tag_name",
                "value": "think",
                "display_name": "Think tag Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the tag to extract",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Extracts content inside specified tags and text after the tag.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Extract Think Component",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "output",
                "hidden": null,
                "display_name": "Extracted Data",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "tag_name"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "ExtractThinkComponent",
          "id": "ExtractThinkComponent-9uWtd"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 332
        },
        "dragging": false
      },
      {
        "id": "ParseData-8gLWu",
        "type": "genericNode",
        "position": {
          "x": 3342.8008893913525,
          "y": 1661.4394884720498
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "({date}) {message}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "ParseData",
          "id": "ParseData-8gLWu"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 341
        }
      },
      {
        "id": "CurrentDate-fnI8v",
        "type": "genericNode",
        "position": {
          "x": 1735.0969743546375,
          "y": 2184.9842446705607
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from datetime import datetime\nfrom zoneinfo import ZoneInfo, available_timezones\n\nfrom loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import DropdownInput, Output\nfrom langflow.schema.message import Message\n\n\nclass CurrentDateComponent(Component):\n    display_name = \"Current Date\"\n    description = \"Returns the current date and time in the selected timezone.\"\n    icon = \"clock\"\n    name = \"CurrentDate\"\n\n    inputs = [\n        DropdownInput(\n            name=\"timezone\",\n            display_name=\"Timezone\",\n            options=list(available_timezones()),\n            value=\"UTC\",\n            info=\"Select the timezone for the current date and time.\",\n            tool_mode=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\n    ]\n\n    def get_current_date(self) -> Message:\n        try:\n            tz = ZoneInfo(self.timezone)\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n            result = f\"{current_date}\"\n            self.status = result\n            return Message(text=result)\n        except Exception as e:  # noqa: BLE001\n            logger.opt(exception=True).debug(\"Error getting current date\")\n            error_message = f\"Error: {e}\"\n            self.status = error_message\n            return Message(text=error_message)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "timezone": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "Asia/Ho_Chi_Minh",
                  "GMT+0",
                  "America/Dominica",
                  "Pacific/Saipan",
                  "Europe/Samara",
                  "America/Regina",
                  "Antarctica/Mawson",
                  "Africa/Libreville",
                  "Atlantic/St_Helena",
                  "Antarctica/Palmer",
                  "Etc/GMT-3",
                  "Jamaica",
                  "Atlantic/Faeroe",
                  "GB",
                  "Europe/London",
                  "America/St_Vincent",
                  "Asia/Anadyr",
                  "Etc/GMT+11",
                  "Africa/Mbabane",
                  "America/Rankin_Inlet",
                  "MET",
                  "America/Havana",
                  "Etc/GMT0",
                  "Europe/Zagreb",
                  "America/Port-au-Prince",
                  "America/Manaus",
                  "Europe/Bucharest",
                  "Brazil/Acre",
                  "US/Indiana-Starke",
                  "ROC",
                  "Arctic/Longyearbyen",
                  "America/Recife",
                  "Africa/Cairo",
                  "Etc/Universal",
                  "Etc/GMT+1",
                  "Africa/Tripoli",
                  "America/Argentina/Salta",
                  "Canada/Atlantic",
                  "Asia/Hovd",
                  "America/Nuuk",
                  "Pacific/Kanton",
                  "Europe/Skopje",
                  "Europe/Helsinki",
                  "Asia/Kuching",
                  "Asia/Qostanay",
                  "Asia/Yekaterinburg",
                  "Pacific/Galapagos",
                  "America/Porto_Acre",
                  "America/Grand_Turk",
                  "Asia/Seoul",
                  "America/St_Thomas",
                  "Africa/Dakar",
                  "Europe/Kyiv",
                  "Canada/Eastern",
                  "Egypt",
                  "Etc/GMT-7",
                  "Asia/Jerusalem",
                  "Canada/Saskatchewan",
                  "Asia/Krasnoyarsk",
                  "Africa/Addis_Ababa",
                  "America/Inuvik",
                  "Asia/Damascus",
                  "America/Puerto_Rico",
                  "America/Indiana/Tell_City",
                  "UCT",
                  "Asia/Kuwait",
                  "Europe/Nicosia",
                  "Indian/Antananarivo",
                  "America/Adak",
                  "Africa/Johannesburg",
                  "Australia/ACT",
                  "Asia/Baghdad",
                  "US/Alaska",
                  "Africa/Sao_Tome",
                  "America/Argentina/Jujuy",
                  "Etc/GMT-6",
                  "Asia/Jakarta",
                  "Atlantic/Reykjavik",
                  "Pacific/Nauru",
                  "Asia/Vientiane",
                  "Australia/Perth",
                  "America/Tijuana",
                  "Navajo",
                  "Europe/Budapest",
                  "Australia/Queensland",
                  "America/Porto_Velho",
                  "Asia/Chungking",
                  "Asia/Kolkata",
                  "America/North_Dakota/Center",
                  "Etc/GMT-9",
                  "America/Monterrey",
                  "Pacific/Samoa",
                  "Canada/Yukon",
                  "Antarctica/DumontDUrville",
                  "America/St_Barthelemy",
                  "US/Pacific",
                  "America/Anchorage",
                  "Africa/Dar_es_Salaam",
                  "Asia/Chita",
                  "America/Miquelon",
                  "Pacific/Tahiti",
                  "America/Guyana",
                  "Asia/Istanbul",
                  "America/Santarem",
                  "Atlantic/South_Georgia",
                  "Libya",
                  "America/Phoenix",
                  "Etc/GMT-2",
                  "Etc/GMT+10",
                  "Canada/Central",
                  "America/Edmonton",
                  "Europe/Tiraspol",
                  "Zulu",
                  "Africa/Khartoum",
                  "Canada/Mountain",
                  "Asia/Dacca",
                  "Africa/Abidjan",
                  "America/Argentina/Rio_Gallegos",
                  "Pacific/Easter",
                  "Australia/Hobart",
                  "Asia/Pyongyang",
                  "Antarctica/Troll",
                  "Asia/Thimphu",
                  "America/North_Dakota/New_Salem",
                  "Asia/Bishkek",
                  "CST6CDT",
                  "America/Metlakatla",
                  "America/Antigua",
                  "America/Santiago",
                  "Indian/Cocos",
                  "Australia/NSW",
                  "America/Indianapolis",
                  "Asia/Pontianak",
                  "Antarctica/Davis",
                  "Indian/Chagos",
                  "Kwajalein",
                  "Australia/Eucla",
                  "Africa/Monrovia",
                  "America/Maceio",
                  "Asia/Kashgar",
                  "America/Campo_Grande",
                  "Africa/Kinshasa",
                  "Africa/Algiers",
                  "Indian/Mauritius",
                  "UTC",
                  "Asia/Tel_Aviv",
                  "Africa/Ndjamena",
                  "Europe/Belgrade",
                  "CET",
                  "Pacific/Noumea",
                  "America/Kralendijk",
                  "Asia/Karachi",
                  "Etc/GMT+4",
                  "Australia/South",
                  "America/Vancouver",
                  "America/Louisville",
                  "EST5EDT",
                  "Africa/Lagos",
                  "America/Santa_Isabel",
                  "America/Managua",
                  "ROK",
                  "America/Moncton",
                  "Antarctica/Macquarie",
                  "America/Tortola",
                  "Indian/Mayotte",
                  "Asia/Bangkok",
                  "Africa/Harare",
                  "America/Yakutat",
                  "Asia/Beirut",
                  "Etc/GMT+12",
                  "Asia/Hong_Kong",
                  "Africa/Luanda",
                  "GMT-0",
                  "Iceland",
                  "America/Anguilla",
                  "America/Guadeloupe",
                  "Africa/El_Aaiun",
                  "Indian/Kerguelen",
                  "Atlantic/Azores",
                  "America/Mendoza",
                  "Asia/Oral",
                  "Asia/Novokuznetsk",
                  "America/Thunder_Bay",
                  "Pacific/Midway",
                  "America/Rainy_River",
                  "America/Araguaina",
                  "America/Cancun",
                  "America/Detroit",
                  "America/Kentucky/Louisville",
                  "Australia/LHI",
                  "America/Rio_Branco",
                  "Pacific/Fakaofo",
                  "America/Eirunepe",
                  "Europe/Paris",
                  "Pacific/Kwajalein",
                  "America/St_Kitts",
                  "MST7MDT",
                  "Etc/Greenwich",
                  "Europe/Kirov",
                  "America/Rosario",
                  "Etc/GMT+5",
                  "America/Curacao",
                  "Asia/Kathmandu",
                  "Hongkong",
                  "Europe/Astrakhan",
                  "Pacific/Pago_Pago",
                  "America/Montreal",
                  "Europe/Copenhagen",
                  "Asia/Tomsk",
                  "Europe/Moscow",
                  "America/Matamoros",
                  "America/Resolute",
                  "Antarctica/Syowa",
                  "Brazil/DeNoronha",
                  "Africa/Ouagadougou",
                  "Asia/Vladivostok",
                  "America/Yellowknife",
                  "Asia/Nicosia",
                  "Africa/Juba",
                  "Asia/Tokyo",
                  "Pacific/Port_Moresby",
                  "Atlantic/Canary",
                  "Asia/Irkutsk",
                  "Africa/Accra",
                  "Etc/GMT-4",
                  "America/Halifax",
                  "GMT",
                  "Atlantic/Madeira",
                  "US/Hawaii",
                  "Europe/Stockholm",
                  "Asia/Tashkent",
                  "Africa/Nouakchott",
                  "Etc/GMT-5",
                  "Asia/Almaty",
                  "Australia/Adelaide",
                  "Australia/West",
                  "GMT0",
                  "Africa/Porto-Novo",
                  "Africa/Maseru",
                  "America/Argentina/Mendoza",
                  "America/Indiana/Vincennes",
                  "Etc/GMT-12",
                  "Europe/Ljubljana",
                  "Europe/Sofia",
                  "Europe/Amsterdam",
                  "Australia/Yancowinna",
                  "America/Montevideo",
                  "Asia/Yangon",
                  "Europe/Athens",
                  "Africa/Lubumbashi",
                  "Pacific/Efate",
                  "America/Indiana/Marengo",
                  "Asia/Amman",
                  "Europe/Chisinau",
                  "Pacific/Tarawa",
                  "Africa/Malabo",
                  "America/Bahia_Banderas",
                  "Singapore",
                  "Asia/Tehran",
                  "Portugal",
                  "America/Bogota",
                  "Etc/GMT-10",
                  "Indian/Christmas",
                  "America/Indiana/Knox",
                  "America/Swift_Current",
                  "Africa/Kigali",
                  "Etc/GMT+0",
                  "Europe/Dublin",
                  "Pacific/Enderbury",
                  "Asia/Ust-Nera",
                  "Pacific/Pohnpei",
                  "Indian/Reunion",
                  "Africa/Douala",
                  "America/Lima",
                  "America/Menominee",
                  "Europe/Luxembourg",
                  "Pacific/Chuuk",
                  "Etc/GMT-11",
                  "Asia/Macau",
                  "America/Guayaquil",
                  "America/Indiana/Petersburg",
                  "America/Indiana/Winamac",
                  "Europe/Uzhgorod",
                  "America/Chicago",
                  "America/Creston",
                  "Indian/Comoro",
                  "Asia/Kabul",
                  "America/Iqaluit",
                  "US/Aleutian",
                  "Asia/Famagusta",
                  "Africa/Nairobi",
                  "America/Fortaleza",
                  "America/Buenos_Aires",
                  "Pacific/Rarotonga",
                  "Africa/Banjul",
                  "America/Blanc-Sablon",
                  "Asia/Chongqing",
                  "Europe/Tirane",
                  "Mexico/BajaNorte",
                  "Pacific/Guam",
                  "Atlantic/Bermuda",
                  "Cuba",
                  "Europe/Andorra",
                  "America/Sao_Paulo",
                  "America/Chihuahua",
                  "Europe/Saratov",
                  "Pacific/Tongatapu",
                  "Europe/Monaco",
                  "Asia/Yakutsk",
                  "Europe/Gibraltar",
                  "Pacific/Kosrae",
                  "WET",
                  "Pacific/Honolulu",
                  "America/Caracas",
                  "Europe/Simferopol",
                  "Europe/Minsk",
                  "America/Atka",
                  "Asia/Muscat",
                  "US/Central",
                  "Universal",
                  "Asia/Brunei",
                  "Asia/Macao",
                  "Pacific/Funafuti",
                  "Asia/Ujung_Pandang",
                  "America/Boa_Vista",
                  "Africa/Asmera",
                  "America/Aruba",
                  "America/Argentina/Buenos_Aires",
                  "Asia/Yerevan",
                  "Europe/Rome",
                  "NZ-CHAT",
                  "Asia/Aqtobe",
                  "Pacific/Wake",
                  "America/Virgin",
                  "America/Nassau",
                  "America/Argentina/ComodRivadavia",
                  "Antarctica/Vostok",
                  "America/Mexico_City",
                  "Israel",
                  "America/Argentina/San_Juan",
                  "Africa/Freetown",
                  "Australia/Lord_Howe",
                  "Asia/Ulaanbaatar",
                  "Europe/Ulyanovsk",
                  "Africa/Ceuta",
                  "America/Toronto",
                  "America/Bahia",
                  "Asia/Srednekolymsk",
                  "America/Hermosillo",
                  "Europe/Istanbul",
                  "America/Goose_Bay",
                  "PRC",
                  "Africa/Asmara",
                  "Asia/Ulan_Bator",
                  "Asia/Hebron",
                  "GB-Eire",
                  "Europe/Mariehamn",
                  "Australia/Tasmania",
                  "America/Guatemala",
                  "Europe/Riga",
                  "America/Port_of_Spain",
                  "Asia/Kuala_Lumpur",
                  "Asia/Khandyga",
                  "Europe/Vaduz",
                  "Greenwich",
                  "America/Panama",
                  "Australia/Melbourne",
                  "America/Fort_Nelson",
                  "America/Mazatlan",
                  "Africa/Bujumbura",
                  "America/Juneau",
                  "Pacific/Kiritimati",
                  "MST",
                  "America/Thule",
                  "Australia/Lindeman",
                  "Asia/Aden",
                  "Europe/Kaliningrad",
                  "Canada/Newfoundland",
                  "America/Scoresbysund",
                  "Africa/Blantyre",
                  "America/Argentina/Tucuman",
                  "Atlantic/Cape_Verde",
                  "Pacific/Gambier",
                  "Asia/Kamchatka",
                  "Australia/Broken_Hill",
                  "Europe/Madrid",
                  "America/Montserrat",
                  "America/Costa_Rica",
                  "Africa/Tunis",
                  "Europe/Prague",
                  "America/Atikokan",
                  "Antarctica/McMurdo",
                  "PST8PDT",
                  "Etc/GMT-8",
                  "Brazil/East",
                  "America/Knox_IN",
                  "Europe/Vienna",
                  "Europe/Vilnius",
                  "America/La_Paz",
                  "Pacific/Guadalcanal",
                  "Africa/Timbuktu",
                  "Europe/Volgograd",
                  "America/Pangnirtung",
                  "Poland",
                  "America/Ojinaga",
                  "Antarctica/Casey",
                  "America/Argentina/Ushuaia",
                  "Indian/Mahe",
                  "Pacific/Niue",
                  "Etc/GMT-1",
                  "America/Nome",
                  "America/Jamaica",
                  "Europe/Berlin",
                  "Asia/Aqtau",
                  "Antarctica/Rothera",
                  "Australia/Canberra",
                  "America/Merida",
                  "Europe/Brussels",
                  "Africa/Bamako",
                  "Australia/Currie",
                  "Asia/Shanghai",
                  "Etc/GMT+7",
                  "Europe/Lisbon",
                  "Europe/Jersey",
                  "Africa/Bissau",
                  "Asia/Thimbu",
                  "America/Grenada",
                  "Asia/Colombo",
                  "Factory",
                  "Europe/Vatican",
                  "Europe/Warsaw",
                  "America/Paramaribo",
                  "Africa/Gaborone",
                  "Etc/GMT-14",
                  "NZ",
                  "Africa/Djibouti",
                  "Asia/Harbin",
                  "America/Martinique",
                  "US/Arizona",
                  "Eire",
                  "Chile/EasterIsland",
                  "Africa/Mogadishu",
                  "Africa/Brazzaville",
                  "Asia/Sakhalin",
                  "Asia/Rangoon",
                  "Asia/Barnaul",
                  "Etc/GMT-13",
                  "America/Cordoba",
                  "Asia/Dubai",
                  "America/Argentina/Cordoba",
                  "America/Tegucigalpa",
                  "Asia/Singapore",
                  "Asia/Katmandu",
                  "Mexico/General",
                  "America/Cuiaba",
                  "Pacific/Ponape",
                  "Asia/Phnom_Penh",
                  "Africa/Conakry",
                  "Asia/Novosibirsk",
                  "America/Indiana/Vevay",
                  "America/Cayenne",
                  "America/Kentucky/Monticello",
                  "America/Noronha",
                  "Africa/Kampala",
                  "Atlantic/Stanley",
                  "US/Eastern",
                  "Etc/GMT-0",
                  "America/Punta_Arenas",
                  "Australia/Brisbane",
                  "Pacific/Fiji",
                  "Australia/North",
                  "America/Godthab",
                  "Asia/Manila",
                  "America/Fort_Wayne",
                  "Pacific/Bougainville",
                  "Turkey",
                  "Etc/GMT",
                  "America/Dawson",
                  "America/Indiana/Indianapolis",
                  "America/Barbados",
                  "Indian/Maldives",
                  "America/Cambridge_Bay",
                  "Pacific/Yap",
                  "Etc/GMT+3",
                  "Asia/Baku",
                  "Pacific/Truk",
                  "Asia/Omsk",
                  "Pacific/Marquesas",
                  "Africa/Windhoek",
                  "Asia/Saigon",
                  "Asia/Atyrau",
                  "Europe/Kiev",
                  "US/Samoa",
                  "Etc/GMT+9",
                  "Etc/GMT+2",
                  "Asia/Ashkhabad",
                  "Europe/San_Marino",
                  "Europe/Malta",
                  "Pacific/Pitcairn",
                  "America/New_York",
                  "Canada/Pacific",
                  "EET",
                  "US/East-Indiana",
                  "Asia/Samarkand",
                  "Asia/Choibalsan",
                  "America/Los_Angeles",
                  "Europe/Guernsey",
                  "Africa/Niamey",
                  "Iran",
                  "America/Marigot",
                  "Europe/Bratislava",
                  "Europe/Busingen",
                  "Pacific/Apia",
                  "America/Nipigon",
                  "America/Coral_Harbour",
                  "Asia/Dushanbe",
                  "Etc/UTC",
                  "America/Argentina/San_Luis",
                  "Asia/Dhaka",
                  "Asia/Makassar",
                  "Antarctica/South_Pole",
                  "Etc/Zulu",
                  "Asia/Taipei",
                  "Japan",
                  "Asia/Urumqi",
                  "America/St_Johns",
                  "America/Argentina/Catamarca",
                  "Africa/Maputo",
                  "Pacific/Wallis",
                  "America/Sitka",
                  "Pacific/Chatham",
                  "Africa/Lusaka",
                  "America/Ensenada",
                  "Asia/Qyzylorda",
                  "America/Boise",
                  "Chile/Continental",
                  "America/Dawson_Creek",
                  "Africa/Casablanca",
                  "America/Belize",
                  "America/Danmarkshavn",
                  "Brazil/West",
                  "Asia/Riyadh",
                  "Europe/Belfast",
                  "America/St_Lucia",
                  "Africa/Lome",
                  "Europe/Zurich",
                  "America/Asuncion",
                  "Pacific/Norfolk",
                  "Europe/Sarajevo",
                  "Asia/Bahrain",
                  "Australia/Darwin",
                  "America/Whitehorse",
                  "America/Santo_Domingo",
                  "Asia/Jayapura",
                  "America/Glace_Bay",
                  "Etc/GMT+6",
                  "America/North_Dakota/Beulah",
                  "America/Ciudad_Juarez",
                  "America/Jujuy",
                  "HST",
                  "Australia/Victoria",
                  "America/Lower_Princes",
                  "Europe/Oslo",
                  "Asia/Dili",
                  "Australia/Sydney",
                  "America/El_Salvador",
                  "Asia/Tbilisi",
                  "Pacific/Majuro",
                  "Etc/GMT+8",
                  "EST",
                  "America/Denver",
                  "Atlantic/Jan_Mayen",
                  "Pacific/Johnston",
                  "W-SU",
                  "Etc/UCT",
                  "Europe/Isle_of_Man",
                  "Asia/Qatar",
                  "US/Mountain",
                  "America/Argentina/La_Rioja",
                  "America/Winnipeg",
                  "America/Belem",
                  "Pacific/Palau",
                  "America/Shiprock",
                  "America/Catamarca",
                  "Europe/Tallinn",
                  "Africa/Bangui",
                  "Mexico/BajaSur",
                  "Atlantic/Faroe",
                  "Asia/Calcutta",
                  "Europe/Podgorica",
                  "Asia/Gaza",
                  "US/Michigan",
                  "Asia/Magadan",
                  "Asia/Ashgabat",
                  "Europe/Zaporozhye",
                  "Pacific/Auckland",
                  "America/Cayman"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timezone",
                "value": "Asia/Omsk",
                "display_name": "Timezone",
                "advanced": false,
                "dynamic": false,
                "info": "Select the timezone for the current date and time.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              }
            },
            "description": "Returns the current date and time in the selected timezone.",
            "icon": "clock",
            "base_classes": [
              "Message"
            ],
            "display_name": "Current Date",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "current_date",
                "hidden": null,
                "display_name": "Current Date",
                "method": "get_current_date",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "timezone"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "CurrentDate",
          "id": "CurrentDate-fnI8v"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 249
        },
        "dragging": false
      },
      {
        "id": "UpdateData-wcVSA",
        "type": "genericNode",
        "position": {
          "x": 3046.963719663119,
          "y": 2094.8845366523874
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "old_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "old_data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The record to update.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DataInput,\n    DictInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass UpdateDataComponent(Component):\n    display_name: str = \"Update Data\"\n    description: str = \"Dynamically update or append data with the specified fields.\"\n    name: str = \"UpdateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    icon = \"FolderSync\"\n\n    inputs = [\n        DataInput(\n            name=\"old_data\",\n            display_name=\"Data\",\n            info=\"The record to update.\",\n            is_list=True,  # Changed to True to handle list of Data objects\n            required=True,\n        ),\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=0,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update the build configuration when the number of fields changes.\n\n        Args:\n            build_config (dotdict): The current build configuration.\n            field_value (Any): The new value for the field.\n            field_name (Optional[str]): The name of the field being updated.\n        \"\"\"\n        if field_name == \"number_of_fields\":\n            default_keys = {\n                \"code\",\n                \"_type\",\n                \"number_of_fields\",\n                \"text_key\",\n                \"old_data\",\n                \"text_key_validator\",\n            }\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = f\"Number of fields cannot exceed {self.MAX_FIELDS}. Try using a Component to combine two Data.\"\n                raise ValueError(msg)\n\n            existing_fields = {}\n            # Back up the existing template fields\n            for key in list(build_config.keys()):\n                if key not in default_keys:\n                    existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data | list[Data]:\n        \"\"\"Build the updated data by combining the old data with new fields.\"\"\"\n        new_data = self.get_data()\n        if isinstance(self.old_data, list):\n            for data_item in self.old_data:\n                if not isinstance(data_item, Data):\n                    continue  # Skip invalid items\n                data_item.data.update(new_data)\n                if self.text_key:\n                    data_item.text_key = self.text_key\n                self.validate_text_key(data_item)\n            self.status = self.old_data\n            return self.old_data  # Returns List[Data]\n        if isinstance(self.old_data, Data):\n            self.old_data.data.update(new_data)\n            if self.text_key:\n                self.old_data.text_key = self.text_key\n            self.status = self.old_data\n            self.validate_text_key(self.old_data)\n            return self.old_data  # Returns Data\n        msg = \"old_data is not a Data object or list of Data objects.\"\n        raise ValueError(msg)\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        default_keys = {\n            \"code\",\n            \"_type\",\n            \"number_of_fields\",\n            \"text_key\",\n            \"old_data\",\n            \"text_key_validator\",\n        }\n        for attr_name, attr_value in self._attributes.items():\n            if attr_name in default_keys:\n                continue  # Skip default attributes\n            if isinstance(attr_value, dict):\n                for key, value in attr_value.items():\n                    data[key] = value.get_text() if isinstance(value, Data) else value\n            elif isinstance(attr_value, Data):\n                data[attr_name] = attr_value.get_text()\n            else:\n                data[attr_name] = attr_value\n        return data\n\n    def validate_text_key(self, data: Data) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = data.data.keys()\n        if self.text_key and self.text_key not in data_keys:\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: {', '.join(data_keys)}\"\n            raise ValueError(msg)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_fields": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "int",
                  "min": 1,
                  "max": 15,
                  "step": 1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_fields",
                "value": 1,
                "display_name": "Number of Fields",
                "advanced": false,
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "text_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key",
                "value": "",
                "display_name": "Text Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text_key_validator": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key_validator",
                "value": false,
                "display_name": "Text Key Validator",
                "advanced": true,
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "field_1_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "field_1_key",
                "value": {
                  "date": ""
                },
                "display_name": "Field 1",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Data"
                ],
                "dynamic": false,
                "info": "Key for field 1.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              }
            },
            "description": "Dynamically update or append data with the specified fields.",
            "icon": "FolderSync",
            "base_classes": [
              "Data"
            ],
            "display_name": "Update Data",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "hidden": null,
                "display_name": "Data",
                "method": "build_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "old_data",
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "UpdateData",
          "id": "UpdateData-wcVSA"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        },
        "dragging": false
      },
      {
        "id": "Directory-AYfEg",
        "type": "genericNode",
        "position": {
          "x": 2534.095567246957,
          "y": 736.6903019913353
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput, MultiselectInput\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from. Defaults to current directory ('.')\",\n            value=\".\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"types\",\n            display_name=\"File Types\",\n            info=\"File types to load. Select one or more types or leave empty to load all supported types.\",\n            options=TEXT_FILE_TYPES,\n            value=[],\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = self.types\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n\n        # If no types are specified, use all supported types\n        if not types:\n            types = TEXT_FILE_TYPES\n\n        # Check if all specified types are valid\n        invalid_types = [t for t in types if t not in TEXT_FILE_TYPES]\n        if invalid_types:\n            msg = f\"Invalid file types specified: {invalid_types}. Valid types are: {TEXT_FILE_TYPES}\"\n            raise ValueError(msg)\n\n        valid_types = types\n\n        file_paths = retrieve_file_paths(\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=valid_types\n        )\n\n        loaded_data = []\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\n\n        valid_data = [x for x in loaded_data if x is not None and isinstance(x, Data)]\n        self.status = valid_data\n        return valid_data\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.load_directory())\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "depth": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "depth",
                "value": 0,
                "display_name": "Depth",
                "advanced": false,
                "dynamic": false,
                "info": "Depth to search for files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "load_hidden": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "load_hidden",
                "value": false,
                "display_name": "Load Hidden",
                "advanced": true,
                "dynamic": false,
                "info": "If true, hidden files will be loaded.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_concurrency": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_concurrency",
                "value": 2,
                "display_name": "Max Concurrency",
                "advanced": true,
                "dynamic": false,
                "info": "Maximum concurrency for loading files.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "path": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "path",
                "value": "Promts\\veo\\",
                "display_name": "Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Path to the directory to load files from. Defaults to current directory ('.')",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "recursive": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "recursive",
                "value": false,
                "display_name": "Recursive",
                "advanced": true,
                "dynamic": false,
                "info": "If true, the search will be recursive.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "silent_errors": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "silent_errors",
                "value": false,
                "display_name": "Silent Errors",
                "advanced": true,
                "dynamic": false,
                "info": "If true, errors will not raise an exception.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "types": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx"
                ],
                "combobox": false,
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "types",
                "value": [
                  "txt"
                ],
                "display_name": "File Types",
                "advanced": false,
                "dynamic": false,
                "info": "File types to load. Select one or more types or leave empty to load all supported types.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultiselectInput"
              },
              "use_multithreading": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "use_multithreading",
                "value": false,
                "display_name": "Use Multithreading",
                "advanced": true,
                "dynamic": false,
                "info": "If true, multithreading will be used.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Recursively load files from a directory.",
            "icon": "folder",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "Directory",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "load_directory",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "dataframe",
                "display_name": "DataFrame",
                "method": "as_dataframe",
                "value": "__UNDEFINED__",
                "cache": true,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "path",
              "types",
              "depth",
              "max_concurrency",
              "load_hidden",
              "recursive",
              "silent_errors",
              "use_multithreading"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "Directory",
          "id": "Directory-AYfEg"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 442
        },
        "dragging": false
      },
      {
        "id": "CharacterTextSplitter-G9F3b",
        "type": "genericNode",
        "position": {
          "x": 833.4864926691369,
          "y": 87.01483055274193
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data_input": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data_input",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Document",
                  "Data"
                ],
                "dynamic": false,
                "info": "The texts to split.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "chunk_overlap": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_overlap",
                "value": 200,
                "display_name": "Chunk Overlap",
                "advanced": false,
                "dynamic": false,
                "info": "The amount of overlap between chunks.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "chunk_size": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum length of each chunk.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langchain_text_splitters import CharacterTextSplitter, TextSplitter\n\nfrom langflow.base.textsplitters.model import LCTextSplitterComponent\nfrom langflow.inputs import DataInput, IntInput, MessageTextInput\nfrom langflow.utils.util import unescape_string\n\n\nclass CharacterTextSplitterComponent(LCTextSplitterComponent):\n    display_name = \"CharacterTextSplitter\"\n    description = \"Split text by number of characters.\"\n    documentation = \"https://docs.langflow.org/components/text-splitters#charactertextsplitter\"\n    name = \"CharacterTextSplitter\"\n    icon = \"LangChain\"\n\n    inputs = [\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum length of each chunk.\",\n            value=1000,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"The amount of overlap between chunks.\",\n            value=200,\n        ),\n        DataInput(\n            name=\"data_input\",\n            display_name=\"Input\",\n            info=\"The texts to split.\",\n            input_types=[\"Document\", \"Data\"],\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info='The characters to split on.\\nIf left empty defaults to \"\\\\n\\\\n\".',\n        ),\n    ]\n\n    def get_data_input(self) -> Any:\n        return self.data_input\n\n    def build_text_splitter(self) -> TextSplitter:\n        separator = unescape_string(self.separator) if self.separator else \"\\n\\n\"\n        return CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "separator": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "separator",
                "value": "\\n",
                "display_name": "Separator",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The characters to split on.\nIf left empty defaults to \"\\n\\n\".",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Split text by number of characters.",
            "icon": "LangChain",
            "base_classes": [
              "Data"
            ],
            "display_name": "CharacterTextSplitter",
            "documentation": "https://docs.langflow.org/components/text-splitters#charactertextsplitter",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "transform_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "chunk_size",
              "chunk_overlap",
              "data_input",
              "separator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "CharacterTextSplitter",
          "id": "CharacterTextSplitter-G9F3b"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 439
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-kbNTV",
        "type": "genericNode",
        "position": {
          "x": 1689.3250643729555,
          "y": 898.8129742059363
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_df": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_df",
                "value": "",
                "display_name": "Input DataFrame",
                "advanced": false,
                "input_types": [
                  "DataFrame"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataFrameInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import StrInput, Output, DataFrameInput, MultilineInput\r\nfrom langflow.schema import DataFrame, Data\r\nimport pandas as pd\r\nfrom typing import List\r\n\r\n\r\nclass DataFrameGroupConcatComponent(Component):\r\n    display_name = \"DataFrame Group & Concat\"\r\n    description = \"Group and concatenate DataFrame columns with dynamic patterns\"\r\n    icon = \"Table\"\r\n    category = \"Data Processing\"\r\n\r\n    inputs = [\r\n        DataFrameInput(name=\"input_df\", display_name=\"Input DataFrame\", required=True),\r\n        StrInput(name=\"group_by_columns\", display_name=\"Group By Columns\", required=True),\r\n        StrInput(name=\"concat_columns\", display_name=\"Concat Columns\", required=False),\r\n        MultilineInput(name=\"concat_patterns\", display_name=\"Concat Patterns (with separators)\", required=False)\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Grouped DataFrame\", name=\"grouped_df\", method=\"get_grouped_df\"),\r\n        Output(display_name=\"Grouped Data\", name=\"grouped_data\", method=\"get_grouped_data\")\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.processed_df = pd.DataFrame()\r\n        self.data_objects = []\r\n\r\n    def build(self) -> None:\r\n        self.process_data()\r\n\r\n    def process_data(self):\r\n        try:\r\n            df = self._get_input_df()\r\n            group_cols = self._parse_columns(self.group_by_columns)\r\n            concat_cols = self._parse_columns(self.concat_columns)\r\n            patterns = self._parse_patterns(self.concat_patterns, concat_cols)\r\n\r\n            self._process_dataframe(df, group_cols, concat_cols, patterns)\r\n            self._generate_outputs(group_cols, concat_cols)\r\n\r\n        except Exception as e:\r\n            self.status = str(e)\r\n            self.log(f\"Error: {e}\")\r\n            raise\r\n\r\n    def get_grouped_df(self) -> DataFrame:\r\n        self.process_data()\r\n        return DataFrame(data=self.processed_df.to_dict(\"records\")) if not self.processed_df.empty else None\r\n\r\n    def get_grouped_data(self) -> List[Data]:\r\n        self.process_data()\r\n        return self.data_objects\r\n\r\n    def _get_input_df(self) -> pd.DataFrame:\r\n        if not self.input_df:\r\n            raise ValueError(\"Input DataFrame is required\")\r\n        return pd.DataFrame([item.data for item in self.input_df.to_data_list()])\r\n\r\n    def _parse_columns(self, columns: str) -> List[str]:\r\n        return [col.strip() for col in columns.split(\",\") if col.strip()]\r\n\r\n    def _parse_patterns(self, patterns: str, concat_cols: List[str]) -> List[str]:\r\n        return patterns.split(\"\\n\") if patterns else [\"\\n\"] * len(concat_cols)\r\n\r\n    def _process_dataframe(self, df: pd.DataFrame, group_cols: List[str], concat_cols: List[str], patterns: List[str]):\r\n        agg_rules = {\r\n            col: lambda x, p=patterns[i]: self._format_series(x, p, df)\r\n            for i, col in enumerate(concat_cols)\r\n        }\r\n\r\n        self.processed_df = df.groupby(group_cols, as_index=False).agg(agg_rules)\r\n    \r\n    def _format_series(self, series: pd.Series, pattern: str, df: pd.DataFrame) -> str:\r\n        elements = []\r\n        pattern = pattern.replace('%newLine%', '\\n').replace('%tab%', '    ')\r\n        is_separator = not any(placeholder in pattern for placeholder in ['%value%', '%id%', '{column_name}'])\r\n\r\n        if is_separator:\r\n            return pattern.join(str(val) for val in series.dropna())\r\n        \r\n        for i, val in enumerate(series.dropna()):\r\n            formatted_value = pattern.replace('%value%', str(val))\r\n            formatted_value = formatted_value.replace('%id%', str(i + 1))\r\n\r\n            for col in df.columns:\r\n                value_to_replace = str(df[col].iloc[i]).strip() or 'N/A'\r\n                formatted_value = formatted_value.replace(f'{{{col}}}', value_to_replace)\r\n            \r\n            elements.append(formatted_value)\r\n\r\n        return ''.join(elements)\r\n\r\n    def _generate_outputs(self, group_cols: List[str], concat_cols: List[str]):\r\n        self.data_objects = [\r\n            Data(\r\n                text=\" | \".join(str(row[col]) for col in group_cols),\r\n                data=row.to_dict()\r\n            )\r\n            for _, row in self.processed_df.iterrows()\r\n        ]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "concat_columns": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "concat_columns",
                "value": "text, language, title",
                "display_name": "Concat Columns",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "concat_patterns": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "concat_patterns",
                "value": "Section %id% [{language}]:%newLine%%value%\n%newLine%%newLine%\n%newLine%_______________%newLine% ",
                "display_name": "Concat Patterns (with separators)",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "group_by_columns": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "group_by_columns",
                "value": "source, title, description",
                "display_name": "Group By Columns",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Group and concatenate DataFrame columns with dynamic patterns",
            "icon": "Table",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "DataFrame Group & Concat",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "grouped_df",
                "hidden": null,
                "display_name": "Grouped DataFrame",
                "method": "get_grouped_df",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "grouped_data",
                "hidden": null,
                "display_name": "Grouped Data",
                "method": "get_grouped_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_df",
              "group_by_columns",
              "concat_columns",
              "concat_patterns"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "DataFrameGroupConcatComponent",
          "id": "CustomComponent-kbNTV"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 507
        },
        "dragging": false
      },
      {
        "id": "Prompt-c8bSu",
        "type": "genericNode",
        "position": {
          "x": 2098.4234895436703,
          "y": 1055.5063301028183
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "[СПРАВОЧНАЯ ИНФОРМАЦИЯ]  \n<data>  \n{context}  \n</data>\n\n[ИСТОРИЯ ДИАЛОГА]  \n<history>  \n{history}  \n</history>\n\n[ЗАДАЧА АВОКС]:  \n- Прочесть историю диалога, для понимания контекста\n- Учитывая информацию в блоке <data>, в ответить на вопросы клиента.\n- Если информации недостаточно, сообщи об этом и передай диалог Ольге\n- Не копируй текст из <data> дословно. Отвечай вежливо и кратко, сохраняя смысл.  \n- Предложи воспользоваться помощью ассистента, а не ждать Ольгу, если у тебя есть актуальная информация.\n\n**Текущая дата и время в Омске: {date}**\nТекущее сообщение от клиента: {question}\nОтвет от АВОКС:\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "context": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "context",
                "display_name": "context",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "history": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "history",
                "display_name": "history",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "date": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "date",
                "display_name": "date",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "question": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "question",
                "display_name": "question",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "context",
                "history",
                "date",
                "question"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt",
          "id": "Prompt-c8bSu"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 667
        },
        "dragging": false
      },
      {
        "id": "UpdateData-yckPt",
        "type": "genericNode",
        "position": {
          "x": 1269.303633074204,
          "y": 1461.246175226613
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_df": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_df",
                "value": "",
                "display_name": "Input DataFrame",
                "advanced": false,
                "input_types": [
                  "DataFrame"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "other",
                "_input_type": "DataFrameInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import StrInput, Output, DataFrameInput, IntInput, DictInput, MessageTextInput\r\nfrom langflow.schema import DataFrame, Data\r\nimport pandas as pd\r\nfrom typing import List\r\n\r\nclass DataFrameGroupConcatComponent(Component):\r\n    display_name = \"DataFrame Group & Concat\"\r\n    description = \"Group and concatenate DataFrame columns with dynamic patterns\"\r\n    icon = \"Table\"\r\n    category = \"Data Processing\"\r\n    MAX_COLUMNS = 10\r\n\r\n    inputs = [\r\n        DataFrameInput(name=\"input_df\", display_name=\"Input DataFrame\", required=True),\r\n        StrInput(name=\"group_by_columns\", display_name=\"Group By Columns\", required=True, value=\"source\"),\r\n        StrInput(name=\"concat_columns\", display_name=\"Concat Columns\", required=False),\r\n        IntInput(\r\n            name=\"num_concat_columns\",\r\n            display_name=\"Number of Concat Columns\",\r\n            required=True,\r\n            value=0,\r\n            range_spec={\"min\": 0, \"max\": MAX_COLUMNS, \"step\": 1},\r\n            real_time_refresh=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"default_concat_rule\",\r\n            display_name=\"Default Concat Rule\",\r\n            required=False,\r\n            value=\"%newLine%\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Grouped DataFrame\", name=\"grouped_df\", method=\"get_grouped_df\"),\r\n        Output(display_name=\"Grouped Data\", name=\"grouped_data\", method=\"get_grouped_data\"),\r\n    ]\r\n\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.processed_df = pd.DataFrame()\r\n        self.data_objects = []\r\n\r\n    def update_build_config(self, build_config, field_value, field_name=None):\r\n        if field_name == \"num_concat_columns\":\r\n            try:\r\n                field_value_int = int(field_value)\r\n            except ValueError:\r\n                return build_config\r\n\r\n            existing_fields = {key: build_config.pop(key) for key in list(build_config.keys()) if key.startswith(\"concat_rule_and_name_\")}\r\n\r\n            for i in range(1, field_value_int + 1):\r\n                key = f\"concat_rule_and_name_{i}\"\r\n                column_display_name = self._get_column_name(i)\r\n\r\n                if key in existing_fields:\r\n                    build_config[key] = existing_fields[key]\r\n                else:\r\n                    build_config[key] = DictInput(\r\n                        display_name=f\"Concat Rule & New Name for '{column_display_name}'\",\r\n                        name=key,\r\n                        info=f\"First input: concatenation rule for '{column_display_name}' (You can create a specific template using: %value%, %id%, {{columnName}} placeholders).\\n Second input: new column name for '{column_display_name}'.\",\r\n                        input_types=[\"Message\", \"Message\"],\r\n                    ).to_dict()\r\n\r\n            build_config[\"num_concat_columns\"][\"value\"] = field_value_int\r\n        return build_config\r\n\r\n    def build(self) -> None:\r\n        self.process_data()\r\n\r\n    def process_data(self):\r\n        try:\r\n            df = self._get_input_df()\r\n            group_cols = self._parse_columns(self.group_by_columns)\r\n            concat_rules = []\r\n            new_column_names = []\r\n            \r\n            # Для каждого столбца в concat_columns собираем правила\r\n            for i in range(1, self.num_concat_columns + 1):\r\n                key = f\"concat_rule_and_name_{i}\"\r\n                rule, new_name = self._get_concat_rule_and_name(key)\r\n                concat_rules.append(rule)\r\n                new_column_names.append(new_name)\r\n\r\n            self._process_dataframe(df, group_cols, concat_rules, new_column_names)\r\n            self._generate_outputs(group_cols, new_column_names)\r\n        except Exception as e:\r\n            self.status = str(e)\r\n            self.log(f\"Error: {e}\")\r\n            raise\r\n\r\n    def get_grouped_df(self) -> DataFrame:\r\n        self.process_data()\r\n        return DataFrame(data=self.processed_df.to_dict(\"records\")) if not self.processed_df.empty else None\r\n\r\n    def get_grouped_data(self) -> List[Data]:\r\n        self.process_data()\r\n        return self.data_objects\r\n\r\n    def _get_input_df(self) -> pd.DataFrame:\r\n        if not self.input_df:\r\n            raise ValueError(\"Input DataFrame is required\")\r\n        return pd.DataFrame([item.data for item in self.input_df.to_data_list()])\r\n\r\n    def _parse_columns(self, columns: str) -> List[str]:\r\n        return [col.strip() for col in columns.split(\",\") if col.strip()]\r\n\r\n    def _get_column_name(self, index: int) -> str:\r\n        columns = self._parse_columns(self.concat_columns)\r\n        return columns[index - 1] if index <= len(columns) else f\"Column {index}\"\r\n\r\n    def _get_concat_rule_and_name(self, key: str):\r\n        value = getattr(self, key, {})\r\n        rule = value.get(\"Message_1\", \"\") or self.default_concat_rule or \"\"  # Пустое правило, если ничего не задано\r\n        new_name = value.get(\"Message_2\", \"\")\r\n        return rule, new_name\r\n\r\n    def _process_dataframe(self, df: pd.DataFrame, group_cols: List[str], concat_rules: List[str], new_column_names: List[str]):\r\n        # Подготовим агрегации для объединяемых столбцов\r\n        agg_rules = {}\r\n        \r\n        concat_columns = self._parse_columns(self.concat_columns)\r\n        \r\n        for i, (col, rule, new_name) in enumerate(zip(concat_columns, concat_rules, new_column_names)):\r\n            # Для каждого столбца из concat_columns применяем агрегирование\r\n            agg_rules[col] = lambda x, pattern=rule: self._format_series(x, pattern, df)\r\n        \r\n        # Применяем группировку\r\n        self.processed_df = df.groupby(group_cols, as_index=False).agg(agg_rules)\r\n\r\n        # Переименовываем объединенные столбцы\r\n        rename_dict = {concat_columns[i]: new_column_names[i] for i in range(len(new_column_names))}\r\n        self.processed_df.rename(columns=rename_dict, inplace=True)\r\n\r\n    def _format_series(self, series: pd.Series, pattern: str, df: pd.DataFrame) -> str:\r\n        elements = []\r\n        if not pattern:  # Если правила нет, возвращаем просто склеенные значения\r\n            return ''.join(str(val) for val in series.dropna())\r\n\r\n        pattern = pattern.replace('%newLine%', '\\n').replace('%tab%', '    ')\r\n        is_separator = not any(placeholder in pattern for placeholder in ['%value%', '%id%', '{column_name}'])\r\n\r\n        if is_separator:\r\n            return pattern.join(str(val) for val in series.dropna())\r\n\r\n        for i, val in enumerate(series.dropna()):\r\n            formatted_value = pattern.replace('%value%', str(val)).replace('%id%', str(i + 1))\r\n            for col in df.columns:\r\n                value_to_replace = str(df[col].iloc[i]).strip() or 'N/A'\r\n                formatted_value = formatted_value.replace(f'{{{col}}}', value_to_replace)\r\n            elements.append(formatted_value)\r\n\r\n        return ''.join(elements)\r\n\r\n    def _generate_outputs(self, group_cols: List[str], new_column_names: List[str]):\r\n        self.data_objects = [\r\n            Data(\r\n                text=\" | \".join(str(row[col]) for col in group_cols),\r\n                data=row.to_dict()\r\n            )\r\n            for _, row in self.processed_df.iterrows()\r\n        ]\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "concat_columns": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "concat_columns",
                "value": "text, title",
                "display_name": "Concat Columns",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "default_concat_rule": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_concat_rule",
                "value": "%newLine%",
                "display_name": "Default Concat Rule",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "group_by_columns": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "group_by_columns",
                "value": "source",
                "display_name": "Group By Columns",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "num_concat_columns": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 10,
                  "step": 1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "num_concat_columns",
                "value": 1,
                "display_name": "Number of Concat Columns",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "real_time_refresh": true,
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              },
              "concat_rule_and_name_1": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "concat_rule_and_name_1",
                "value": {
                  "": "A"
                },
                "display_name": "Concat Rule & New Name for 'text'",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Message"
                ],
                "dynamic": false,
                "info": "First input: concatenation rule for 'text' (You can create a specific template using: %value%, %id%, {columnName} placeholders).\n Second input: new column name for 'text'.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              }
            },
            "description": "Group and concatenate DataFrame columns with dynamic patterns",
            "icon": "Table",
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "display_name": "DataFrame Group & Concat",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "DataFrame"
                ],
                "selected": "DataFrame",
                "name": "grouped_df",
                "hidden": null,
                "display_name": "Grouped DataFrame",
                "method": "get_grouped_df",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "grouped_data",
                "hidden": null,
                "display_name": "Grouped Data",
                "method": "get_grouped_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_df",
              "group_by_columns",
              "concat_columns",
              "num_concat_columns",
              "default_concat_rule"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "showNode": true,
          "type": "DataFrameGroupConcatComponent",
          "id": "UpdateData-yckPt"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 672
        },
        "dragging": false
      },
      {
        "id": "UpdateData-iKvD5",
        "type": "genericNode",
        "position": {
          "x": 845.6738926148346,
          "y": 1701.3835828889594
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "old_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "old_data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The record to update.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import (\n    BoolInput,\n    DataInput,\n    DictInput,\n    IntInput,\n    MessageTextInput,\n)\nfrom langflow.io import Output\nfrom langflow.schema import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass UpdateDataComponent(Component):\n    display_name: str = \"Update Data\"\n    description: str = \"Dynamically update or append data with the specified fields.\"\n    name: str = \"UpdateData\"\n    MAX_FIELDS = 15  # Define a constant for maximum number of fields\n    icon = \"FolderSync\"\n\n    inputs = [\n        DataInput(\n            name=\"old_data\",\n            display_name=\"Data\",\n            info=\"The record to update.\",\n            is_list=True,  # Changed to True to handle list of Data objects\n            required=True,\n        ),\n        IntInput(\n            name=\"number_of_fields\",\n            display_name=\"Number of Fields\",\n            info=\"Number of fields to be added to the record.\",\n            real_time_refresh=True,\n            value=0,\n            range_spec=RangeSpec(min=1, max=MAX_FIELDS, step=1, step_type=\"int\"),\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"Key that identifies the field to be used as the text content.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"text_key_validator\",\n            display_name=\"Text Key Validator\",\n            advanced=True,\n            info=\"If enabled, checks if the given 'Text Key' is present in the given 'Data'.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"build_data\"),\n    ]\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        \"\"\"Update the build configuration when the number of fields changes.\n\n        Args:\n            build_config (dotdict): The current build configuration.\n            field_value (Any): The new value for the field.\n            field_name (Optional[str]): The name of the field being updated.\n        \"\"\"\n        if field_name == \"number_of_fields\":\n            default_keys = {\n                \"code\",\n                \"_type\",\n                \"number_of_fields\",\n                \"text_key\",\n                \"old_data\",\n                \"text_key_validator\",\n            }\n            try:\n                field_value_int = int(field_value)\n            except ValueError:\n                return build_config\n\n            if field_value_int > self.MAX_FIELDS:\n                build_config[\"number_of_fields\"][\"value\"] = self.MAX_FIELDS\n                msg = f\"Number of fields cannot exceed {self.MAX_FIELDS}. Try using a Component to combine two Data.\"\n                raise ValueError(msg)\n\n            existing_fields = {}\n            # Back up the existing template fields\n            for key in list(build_config.keys()):\n                if key not in default_keys:\n                    existing_fields[key] = build_config.pop(key)\n\n            for i in range(1, field_value_int + 1):\n                key = f\"field_{i}_key\"\n                if key in existing_fields:\n                    field = existing_fields[key]\n                    build_config[key] = field\n                else:\n                    field = DictInput(\n                        display_name=f\"Field {i}\",\n                        name=key,\n                        info=f\"Key for field {i}.\",\n                        input_types=[\"Message\", \"Data\"],\n                    )\n                    build_config[field.name] = field.to_dict()\n\n            build_config[\"number_of_fields\"][\"value\"] = field_value_int\n        return build_config\n\n    async def build_data(self) -> Data | list[Data]:\n        \"\"\"Build the updated data by combining the old data with new fields.\"\"\"\n        new_data = self.get_data()\n        if isinstance(self.old_data, list):\n            for data_item in self.old_data:\n                if not isinstance(data_item, Data):\n                    continue  # Skip invalid items\n                data_item.data.update(new_data)\n                if self.text_key:\n                    data_item.text_key = self.text_key\n                self.validate_text_key(data_item)\n            self.status = self.old_data\n            return self.old_data  # Returns List[Data]\n        if isinstance(self.old_data, Data):\n            self.old_data.data.update(new_data)\n            if self.text_key:\n                self.old_data.text_key = self.text_key\n            self.status = self.old_data\n            self.validate_text_key(self.old_data)\n            return self.old_data  # Returns Data\n        msg = \"old_data is not a Data object or list of Data objects.\"\n        raise ValueError(msg)\n\n    def get_data(self):\n        \"\"\"Function to get the Data from the attributes.\"\"\"\n        data = {}\n        default_keys = {\n            \"code\",\n            \"_type\",\n            \"number_of_fields\",\n            \"text_key\",\n            \"old_data\",\n            \"text_key_validator\",\n        }\n        for attr_name, attr_value in self._attributes.items():\n            if attr_name in default_keys:\n                continue  # Skip default attributes\n            if isinstance(attr_value, dict):\n                for key, value in attr_value.items():\n                    data[key] = value.get_text() if isinstance(value, Data) else value\n            elif isinstance(attr_value, Data):\n                data[attr_name] = attr_value.get_text()\n            else:\n                data[attr_name] = attr_value\n        return data\n\n    def validate_text_key(self, data: Data) -> None:\n        \"\"\"This function validates that the Text Key is one of the keys in the Data.\"\"\"\n        data_keys = data.data.keys()\n        if self.text_key and self.text_key not in data_keys:\n            msg = f\"Text Key: '{self.text_key}' not found in the Data keys: {', '.join(data_keys)}\"\n            raise ValueError(msg)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "number_of_fields": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "int",
                  "min": 1,
                  "max": 15,
                  "step": 1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "number_of_fields",
                "value": 1,
                "display_name": "Number of Fields",
                "advanced": false,
                "dynamic": false,
                "info": "Number of fields to be added to the record.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "text_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key",
                "value": "",
                "display_name": "Text Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Key that identifies the field to be used as the text content.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "text_key_validator": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_key_validator",
                "value": false,
                "display_name": "Text Key Validator",
                "advanced": true,
                "dynamic": false,
                "info": "If enabled, checks if the given 'Text Key' is present in the given 'Data'.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "field_1_key": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "field_1_key",
                "value": {},
                "display_name": "Field 1",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Data"
                ],
                "dynamic": false,
                "info": "Key for field 1.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              }
            },
            "description": "Dynamically update or append data with the specified fields.",
            "icon": "FolderSync",
            "base_classes": [
              "Data"
            ],
            "display_name": "Update Data",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "hidden": null,
                "display_name": "Data",
                "method": "build_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "old_data",
              "number_of_fields",
              "text_key",
              "text_key_validator"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false
          },
          "showNode": true,
          "type": "UpdateData",
          "id": "UpdateData-iKvD5"
        },
        "selected": false,
        "measured": {
          "width": 320,
          "height": 376
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "TextInput-JvrFp",
        "target": "MessagetoData-R0qlr",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-JvrFpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-R0qlrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-TextInput-JvrFp{œdataTypeœ:œTextInputœ,œidœ:œTextInput-JvrFpœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-MessagetoData-R0qlr{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-R0qlrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-JvrFp",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "MessagetoData-R0qlr",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-EmebA",
        "target": "LMStudioModel-z64zV",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-EmebAœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œLMStudioModel-z64zVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-EmebA{œdataTypeœ:œPromptœ,œidœ:œPrompt-EmebAœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LMStudioModel-z64zV{œfieldNameœ:œsystem_messageœ,œidœ:œLMStudioModel-z64zVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-EmebA",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "LMStudioModel-z64zV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "LMStudioEmbeddingsComponent-5YUQf",
        "target": "FAISS-SD53M",
        "sourceHandle": "{œdataTypeœ:œLMStudioEmbeddingsComponentœ,œidœ:œLMStudioEmbeddingsComponent-5YUQfœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "targetHandle": "{œfieldNameœ:œembeddingœ,œidœ:œFAISS-SD53Mœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-LMStudioEmbeddingsComponent-5YUQf{œdataTypeœ:œLMStudioEmbeddingsComponentœ,œidœ:œLMStudioEmbeddingsComponent-5YUQfœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-FAISS-SD53M{œfieldNameœ:œembeddingœ,œidœ:œFAISS-SD53Mœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "LMStudioEmbeddingsComponent",
            "id": "LMStudioEmbeddingsComponent-5YUQf",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embedding",
            "id": "FAISS-SD53M",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "LMStudioModel-z64zV",
        "target": "ExtractThinkComponent-9uWtd",
        "sourceHandle": "{œdataTypeœ:œLMStudioModelœ,œidœ:œLMStudioModel-z64zVœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œExtractThinkComponent-9uWtdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-LMStudioModel-z64zV{œdataTypeœ:œLMStudioModelœ,œidœ:œLMStudioModel-z64zVœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExtractThinkComponent-9uWtd{œfieldNameœ:œinput_valueœ,œidœ:œExtractThinkComponent-9uWtdœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "sourceHandle": {
            "dataType": "LMStudioModel",
            "id": "LMStudioModel-z64zV",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ExtractThinkComponent-9uWtd",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "ParseData-8gLWu",
        "target": "ChatOutput-h1uNY",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8gLWuœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-h1uNYœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-ParseData-8gLWu{œdataTypeœ:œParseDataœ,œidœ:œParseData-8gLWuœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-h1uNY{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-h1uNYœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8gLWu",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-h1uNY",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "ExtractThinkComponent-9uWtd",
        "sourceHandle": "{œdataTypeœ:œExtractThinkComponentœ,œidœ:œExtractThinkComponent-9uWtdœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "UpdateData-wcVSA",
        "targetHandle": "{œfieldNameœ:œold_dataœ,œidœ:œUpdateData-wcVSAœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "old_data",
            "id": "UpdateData-wcVSA",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "ExtractThinkComponent",
            "id": "ExtractThinkComponent-9uWtd",
            "name": "output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__ExtractThinkComponent-9uWtd{œdataTypeœ:œExtractThinkComponentœ,œidœ:œExtractThinkComponent-9uWtdœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-UpdateData-wcVSA{œfieldNameœ:œold_dataœ,œidœ:œUpdateData-wcVSAœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "CurrentDate-fnI8v",
        "sourceHandle": "{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-fnI8vœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "UpdateData-wcVSA",
        "targetHandle": "{œfieldNameœ:œfield_1_keyœ,œidœ:œUpdateData-wcVSAœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "data": {
          "targetHandle": {
            "fieldName": "field_1_key",
            "id": "UpdateData-wcVSA",
            "inputTypes": [
              "Message",
              "Data"
            ],
            "type": "dict"
          },
          "sourceHandle": {
            "dataType": "CurrentDate",
            "id": "CurrentDate-fnI8v",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__CurrentDate-fnI8v{œdataTypeœ:œCurrentDateœ,œidœ:œCurrentDate-fnI8vœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-UpdateData-wcVSA{œfieldNameœ:œfield_1_keyœ,œidœ:œUpdateData-wcVSAœ,œinputTypesœ:[œMessageœ,œDataœ],œtypeœ:œdictœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "UpdateData-wcVSA",
        "sourceHandle": "{œdataTypeœ:œUpdateDataœ,œidœ:œUpdateData-wcVSAœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-8gLWu",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-8gLWuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-8gLWu",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "UpdateData",
            "id": "UpdateData-wcVSA",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__UpdateData-wcVSA{œdataTypeœ:œUpdateDataœ,œidœ:œUpdateData-wcVSAœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-8gLWu{œfieldNameœ:œdataœ,œidœ:œParseData-8gLWuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "URL-h47Jf",
        "sourceHandle": "{œdataTypeœ:œURLœ,œidœ:œURL-h47Jfœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CharacterTextSplitter-G9F3b",
        "targetHandle": "{œfieldNameœ:œdata_inputœ,œidœ:œCharacterTextSplitter-G9F3bœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data_input",
            "id": "CharacterTextSplitter-G9F3b",
            "inputTypes": [
              "Document",
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "URL",
            "id": "URL-h47Jf",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__URL-h47Jf{œdataTypeœ:œURLœ,œidœ:œURL-h47Jfœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-CharacterTextSplitter-G9F3b{œfieldNameœ:œdata_inputœ,œidœ:œCharacterTextSplitter-G9F3bœ,œinputTypesœ:[œDocumentœ,œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "CharacterTextSplitter-G9F3b",
        "sourceHandle": "{œdataTypeœ:œCharacterTextSplitterœ,œidœ:œCharacterTextSplitter-G9F3bœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "FAISS-SD53M",
        "targetHandle": "{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-SD53Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "ingest_data",
            "id": "FAISS-SD53M",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CharacterTextSplitter",
            "id": "CharacterTextSplitter-G9F3b",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__CharacterTextSplitter-G9F3b{œdataTypeœ:œCharacterTextSplitterœ,œidœ:œCharacterTextSplitter-G9F3bœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-FAISS-SD53M{œfieldNameœ:œingest_dataœ,œidœ:œFAISS-SD53Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "ChatInput-mrZxx",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-mrZxxœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "FAISS-SD53M",
        "targetHandle": "{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-SD53Mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "search_query",
            "id": "FAISS-SD53M",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-mrZxx",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ChatInput-mrZxx{œdataTypeœ:œChatInputœ,œidœ:œChatInput-mrZxxœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-FAISS-SD53M{œfieldNameœ:œsearch_queryœ,œidœ:œFAISS-SD53Mœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "FAISS-SD53M",
        "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-SD53Mœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "CustomComponent-kbNTV",
        "targetHandle": "{œfieldNameœ:œinput_dfœ,œidœ:œCustomComponent-kbNTVœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_df",
            "id": "CustomComponent-kbNTV",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-SD53M",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          }
        },
        "id": "xy-edge__FAISS-SD53M{œdataTypeœ:œFAISSœ,œidœ:œFAISS-SD53Mœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-CustomComponent-kbNTV{œfieldNameœ:œinput_dfœ,œidœ:œCustomComponent-kbNTVœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-c8bSu",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-c8bSuœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LMStudioModel-z64zV",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLMStudioModel-z64zVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LMStudioModel-z64zV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-c8bSu",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Prompt-c8bSu{œdataTypeœ:œPromptœ,œidœ:œPrompt-c8bSuœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LMStudioModel-z64zV{œfieldNameœ:œinput_valueœ,œidœ:œLMStudioModel-z64zVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "FAISS-SD53M",
        "sourceHandle": "{œdataTypeœ:œFAISSœ,œidœ:œFAISS-SD53Mœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "UpdateData-yckPt",
        "targetHandle": "{œfieldNameœ:œinput_dfœ,œidœ:œUpdateData-yckPtœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_df",
            "id": "UpdateData-yckPt",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FAISS",
            "id": "FAISS-SD53M",
            "name": "dataframe",
            "output_types": [
              "DataFrame"
            ]
          }
        },
        "id": "xy-edge__FAISS-SD53M{œdataTypeœ:œFAISSœ,œidœ:œFAISS-SD53Mœ,œnameœ:œdataframeœ,œoutput_typesœ:[œDataFrameœ]}-UpdateData-yckPt{œfieldNameœ:œinput_dfœ,œidœ:œUpdateData-yckPtœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 166.5973417074133,
      "y": 26.519505976110736,
      "zoom": 0.3480513823490556
    }
  },
  "description": "AVOX is Vortex Operating Knowledge and eXpert\nАВОКС - это Вихрь Обработки Ключевых Сведений (и эксперт)",
  "name": "AVOX RAG",
  "last_tested_version": "1.2.0",
  "endpoint_name": "avox",
  "is_component": false
}