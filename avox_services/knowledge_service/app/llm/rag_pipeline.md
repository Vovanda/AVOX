# Итеративная обработка документов с LLM

## Алгоритм работы

1. **Инициализация**
   - Создаётся пустой глобальный список фактов (`facts = {}`), где ключ — `id`, а значение содержит текст факта, certainty и reasoning.
   - Инициализируется `previous_answer = ""` — синтезированный ответ предыдущих шагов.
   - Опционально хранится суммаризированная история диалога (`dialog_history`).

2. **Итерация по документам**
   Для каждого документа:
   - Разбить документ на чанки, где каждый чанк имеет `chunk_id` и `chunk_text`.
   - Сформировать запрос к LLM с полями:
     - `question` — текст вопроса пользователя.
     - `document_context` — массив чанков текущего документа.
     - `previous_facts` — текущий список фактов с `id`, текстом, certainty и reasoning.
     - `previous_answer` — синтезированный ответ предыдущих шагов.
     - `dialog_history` — суммарная история переписки (не содержит тексты документов).
   - Получить от LLM ответ с:
     - `answer` — обновлённый ответ по текущим документам.
     - `reasoning` — логическая цепочка рассуждений.
     - `new_facts` — полностью новые факты.
     - `updated_facts` — существующие факты, которые изменились или получили обновлённую certainty.
     - `can_answer` — индикатор того, можно ли дать ответ на вопрос.

3. **Обновление глобального списка фактов**
   - Для каждого факта из `new_facts`:
     - Генерируем уникальный `id` и добавляем факт в глобальный список.
   - Для каждого факта из `updated_facts`:
     - Находим факт по `id` в глобальном списке.
     - Обновляем текст, certainty и reasoning согласно ответу LLM.
     - Если `certainty = "contradicts"`, удаляем или игнорируем факт.
   - Обновляем `previous_answer` текущим `answer`.

4. **Финальная агрегация**
   - После обработки всех документов можно отправить LLM запрос на финальный синтез, передав:
     - Последний `previous_answer`.
     - Накопленные факты (`facts`).
     - Вопрос пользователя (`question`).
   - Модель возвращает окончательный `answer`, `reasoning` и итоговый список фактов.

---

## Формат запроса к LLM

```json
{
  "task": "Инструкция для модели",
  "question": "Текст вопроса пользователя",
  "document_context": [
    {
      "chunk_id": "Уникальный идентификатор чанка",
      "chunk_text": "Текст текущего чанка документа"
    }
  ],
  "previous_facts": [
    {
      "id": "Уникальный идентификатор факта",
      "fact": "Краткое описание факта",
      "certainty": "high|medium|low",
      "reasoning": "Краткая логика или источник факта"
    }
  ],
  "previous_answer": "Синтезированный ответ по предыдущим документам",
  "dialog_history": "Суммарная история переписки"
}
````

---

## Формат ответа LLM

```json
{
  "answer": "Синтезированный ответ на вопрос с учётом текущих документов и фактов",
  "reasoning": "Логическая цепочка рассуждений модели",
  "new_facts": [
    {
      "fact": "Описание нового факта",
      "certainty": "high|medium|low",
      "reasoning": "Обоснование извлечения факта"
    }
  ],
  "updated_facts": [
    {
      "id": "Идентификатор существующего факта",
      "fact": "Обновлённая формулировка или уточнение факта",
      "certainty": "high|medium|low|contradicts",
      "reasoning": "Обоснование обновления или изменения certainty"
    }
  ],
  "can_answer": true|false
}
```
---

### Жёсткий системный промт для итеративного анализа документов

**Роль модели:**
Ты — агент для анализа документов и ответа на вопросы пользователя. Твоя задача — извлекать факты из документов, уточнять существующие факты и формировать итоговый, самодостаточный ответ на вопрос.

**Правила работы:**
1. Всегда получаешь вход в формате JSON с полями:
   * `question` — текст вопроса пользователя
   * `document_context` — массив объектов с `chunk_id` и `chunk_text`
   * `previous_facts` — массив объектов с `id`, `fact`, `certainty`, `reasoning`
   * `previous_answer` — синтезированный ответ предыдущих шагов (для внутреннего использования, не для пользователя)
   * `dialog_history` — история переписки

2. На основе документов и предыдущих фактов:
   * Формируй **итоговый, полный ответ** пользователя в поле `answer`. Он должен быть самодостаточным, понятным и сразу готовым к показу пользователю.
   * Добавляй новые факты в `new_facts`.
   * Обновляй существующие факты в `updated_facts` только если текст или certainty изменились.
   * Не включай в `answer` ссылки на `previous_answer` или промежуточные шаги.

3. JSON-формат ответа:
```json
{
  "answer": "Краткий итоговый ответ, готовый к показу пользователю",
  "reasoning": "Краткая логическая цепочка рассуждений, основанная на документах и фактах",
  "new_facts": [
    {
      "fact": "Описание нового факта",
      "certainty": "high|medium|low",
      "reasoning": "Источник или обоснование"
    }
  ],
  "updated_facts": [
    {
      "id": "Идентификатор существующего факта",
      "fact": "Обновлённый текст факта",
      "certainty": "high|medium|low",
      "reasoning": "Обоснование обновления"
    }
  ],
  "can_answer": true|false
}
```

4. Строгое правило:
* Любой вывод **должен быть корректным JSON**.
* Поле `answer` всегда содержит готовый для пользователя ответ.
* Не добавляй лишних полей, комментариев или текстов вне JSON.
* Не придумывай факты, используй только `document_context`, `previous_facts` и `dialog_history`.

**Цель:**
Создавать аккуратные, точные и самодостаточные ответы на вопрос пользователя, корректно обновлять факты, строго соблюдать JSON-формат и готовность ответа к показу пользователю.


